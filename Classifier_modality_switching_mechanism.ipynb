{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90QG98f9cLNt",
        "outputId": "71d90cd1-24d3-4ab8-a96c-c7c81eac10ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lamini\n",
            "  Downloading lamini-2.5.4-2-py3-none-any.whl (691 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.4/691.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lamini-configuration[yaml] (from lamini)\n",
            "  Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lamini) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lamini) (4.66.4)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from lamini) (1.25.2)\n",
            "Collecting jsonlines (from lamini)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lamini) (2.0.3)\n",
            "Collecting azure-storage-blob (from lamini)\n",
            "  Downloading azure_storage_blob-12.20.0-py3-none-any.whl (392 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.2/392.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from lamini) (3.9.5)\n",
            "Collecting faiss-cpu (from lamini)\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (4.0.3)\n",
            "Collecting azure-core>=1.28.0 (from azure-storage-blob->lamini)\n",
            "  Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (42.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (4.12.2)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob->lamini)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2024.6.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.5.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.22)\n",
            "Installing collected packages: lamini-configuration, jsonlines, isodate, faiss-cpu, azure-core, azure-storage-blob, lamini\n",
            "Successfully installed azure-core-1.30.2 azure-storage-blob-12.20.0 faiss-cpu-1.8.0 isodate-0.6.1 jsonlines-4.0.0 lamini-2.5.4 lamini-configuration-0.8.3\n"
          ]
        }
      ],
      "source": [
        "q!pip install lamini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoxNLzvw7a6H",
        "outputId": "38cad031-97ae-440d-8cc4-66fc98679e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIQNBC_28IwO"
      },
      "outputs": [],
      "source": [
        "!pip install -q python-dotenv gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP_f_fIrf4kL"
      },
      "outputs": [],
      "source": [
        "from lamini import LaminiClassifier\n",
        "\n",
        "llm = LaminiClassifier()\n",
        "\n",
        "prompts = {\n",
        "    \"text_to_text_coding\":\"\"\"Prompts that involve writing, modifying, or understanding code snippets or algorithms.\n",
        "        Examples include writing functions, implementing algorithms, or explaining code logic.\n",
        "        Example: Write a Python function to reverse a string. Another example: Implement the quicksort algorithm in Java.\"\n",
        "    \"\"\",\n",
        "    \"text_to_text_debugging\":\"\"\"Prompts that involve identifying and fixing bugs or errors in code. These prompts usually include a code snippet with a specific issue to be resolved.\n",
        "        Example: Find the bug in this JavaScript code: `function add(a, b) { return a - b; }`. Another example: Debug this Python code to fix the IndexError.\n",
        "    \"\"\",\n",
        "    \"text_to_text_qa\":\"\"\"Prompts that involve asking and answering questions. These can be factual questions, conceptual questions, or any other form of inquiry.\n",
        "        Example: What is the capital of France? Another example: Explain the theory of relativity.\n",
        "    \"\"\",\n",
        "    \"text_to_text_chat\":\"\"\"Prompts that involve normal, casual conversation or chatting. These prompts typically mimic everyday dialogues or social interactions.\n",
        "        Example: How was your day? Another example: What are your plans for the weekend?\n",
        "    \"\"\",\n",
        "    \"image_to_text_description\":\"\"\"Prompts that involve describing the content of an image in detail. These prompts often require identifying objects, scenes, or actions depicted in the image.\n",
        "        Example: Describe the content of this image, including any objects and activities shown. Another example: What is happening in this photo?\n",
        "    \"\"\",\n",
        "    \"image_to_text_ocr\":\"\"\"Prompts that involve extracting text from an image using Optical Character Recognition (OCR) technology. These prompts are focused on recognizing and transcribing text from images.\n",
        "        Example: Extract the text from this image. Another example: Identify and transcribe the text on this sign.\n",
        "    \"\"\",\n",
        "    \"text_to_audio_speech\":\"\"\"Prompts that involve converting written text into spoken words. These prompts are for generating speech audio from text input.\n",
        "        Example: Convert this text to speech: 'Hello, how are you?'. Another example: Generate a speech audio for this paragraph about cimate change.\"\n",
        "    \"\"\",\n",
        "    \"text_to_audio_sound\":\"\"\"Prompts that involve generating specific sounds or sound effects from text descriptions. These prompts focus on creating non-speech audio based on textual descriptions.\n",
        "        Example: Generate a sound of a cat meowing. Another example: Create a sound effect of thunder.\n",
        "    \"\"\",\n",
        "    \"audio_to_text_sound_description\":\"\"\"Prompts that involve listening to an audio clip and describing the sounds heard. These prompts focus on identifying and explaining non-speech sounds.\n",
        "        Example: Listen to this audio and describe the sound. Another example: What animal sounds can you hear in this clip?\n",
        "    \"\"\",\n",
        "    \"audio_to_text_speech_transcription\":\"\"\"Prompts that involve transcribing spoken words from an audio clip into written text. These prompts are focused on converting speech audio to text.\n",
        "        Example: Transcribe this speech audio to text. Another example: Write down the dialogue from this audio recording.\n",
        "    \"\"\",\n",
        "    \"text_to_image_generation\":\"\"\"Prompts that involve generating images based on text descriptions. These prompts require creating visual content that matches the given textual description.\n",
        "        Example: Generate an image of a sunset over the mountains. Another example: Create an illustration of a futuristic city.\n",
        "    \"\"\",\n",
        "    \"text_image_to_image_generation\":\"\"\"Prompts that involve generating new images based on both a base image and additional text descriptions. These prompts focus on modifying or enhancing the base image according to the text input.\n",
        "        Example: Generate an image based on this base image with additional elements. Another example: Add a rainbow to this landscape image.\n",
        "    \"\"\",\n",
        "    \"text_image_to_image_inpainting\":\"\"\"Prompts that involve editing an image by adding or modifying elements within the existing boundaries of the image. These prompts are for in-painting tasks where specific areas of the image are altered.\n",
        "        Example: Edit this image to remove the object in the center. Another example: Fill in the missing parts of this damaged photo.\n",
        "    \"\"\",\n",
        "    \"text_image_to_image_outpainting\":\"\"\"Prompts that involve extending the existing boundaries of an image to create additional content around it. These prompts focus on out-painting tasks where the image is expanded.\n",
        "        Example: Extend the background of this image. Another example: Add more scenery to the edges of this photo.\n",
        "    \"\"\",\n",
        "    \"text_image_to_image_upscaling\":\"\"\"Prompts that involve increasing the resolution of an image. These prompts focus on enhancing the image quality by scaling up its resolution.\n",
        "        Example: Increase the resolution of this image. Another example: Upscale this low-resolution photo to make it clearer.\n",
        "    \"\"\",\n",
        "    \"text_image_to_image_resolution_fix\":\"\"\"Prompts that involve improving the quality of an image's resolution. These prompts focus on fixing or enhancing the resolution to make the image clearer and more detailed.\n",
        "        Example: Improve the resolution quality of this image. Another example: Fix the resolution of this blurry picture.\n",
        "    \"\"\"\n",
        "}\n",
        "import json\n",
        "# saving the system prompts in a json file for a latter use by the LaminiClassifier\n",
        "with open('prompts.json', 'w') as f:\n",
        "    json.dump(prompts, f)\n",
        "    # print message for success\n",
        "    print(\"Prompts saved to prompts.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E63PNfdnbbj"
      },
      "outputs": [],
      "source": [
        "from lamini import LaminiClassifier\n",
        "\n",
        "llm = LaminiClassifier()\n",
        "\n",
        "prompts = [\n",
        "    {\"class_name\":\"text_to_text_coding\",\n",
        "    \"examples\":[\n",
        "      \" Write a Python function to reverse a string. Another \",\n",
        "      \"Implement the quicksort algorithm in Java.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_to_text_debugging\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Find the bug in this JavaScript code: `function add(a, b) { return a - b; }`. Another \",\n",
        "      \"Debug this Python code to fix the IndexError.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_to_text_qa\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" What is the capital of France? Another \",\n",
        "      \"Explain the theory of relativity.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_to_text_chat\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" How was your day? Another \",\n",
        "      \"What are your plans for the weekend?\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"image_to_text_description\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Describe the content of this image, including any objects and activities shown. Another \",\n",
        "      \"What is happening in this photo?\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"image_to_text_ocr\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Extract the text from this image. Another \",\n",
        "      \"Identify and transcribe the text on this sign.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_to_audio_speech\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Convert this text to speech: 'Hello, how are you?'. Another \",\n",
        "      \"Generate a speech audio for this paragraph about cimate change.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_to_audio_sound\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Generate a sound of a cat meowing. Another \",\n",
        "      \"Create a sound effect of thunder.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"audio_to_text_sound_description\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Listen to this audio and describe the sound. Another \",\n",
        "      \"What animal sounds can you hear in this clip?\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"audio_to_text_speech_transcription\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Transcribe this speech audio to text. Another \",\n",
        "      \"Write down the dialogue from this audio recording.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_to_image_generation\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Generate an image of a sunset over the mountains. Another \",\n",
        "      \"Create an illustration of a futuristic city.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_image_to_image_generation\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Generate an image based on this base image with additional elements. Another \",\n",
        "      \"Add a rainbow to this landscape image.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_image_to_image_inpainting\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Edit this image to remove the object in the center. Another \",\n",
        "      \"Fill in the missing parts of this damaged photo.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_image_to_image_outpainting\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Extend the background of this image. Another \",\n",
        "      \"Add more scenery to the edges of this photo.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_image_to_image_upscaling\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Increase the resolution of this image. Another \",\n",
        "      \"Upscale this low-resolution photo to make it clearer.\"\n",
        "    ]\n",
        "    },\n",
        "\n",
        "    {\"class_name\":\"text_image_to_image_resolution_fix\",\n",
        "\n",
        "    \"examples\":[\n",
        "      \" Improve the resolution quality of this image. Another \",\n",
        "      \"Fix the resolution of this blurry picture.\"\n",
        "    ]\n",
        "    },\n",
        "]\n",
        "import json\n",
        "# saving the system prompts in a json file for a latter use by the LaminiClassifier\n",
        "with open('prompts.json', 'w') as f:\n",
        "    json.dump(prompts, f)\n",
        "    # print message for success\n",
        "    print(\"Prompts saved to prompts.json\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h5yQC4GkuyZ"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "# loading the prompts.json file from the harddrive and showing sample data of it\n",
        "with open('prompts.json', 'r') as f:\n",
        "    prompts = json.load(f)\n",
        "    pprint(prompts[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmfIlMZMumIs"
      },
      "outputs": [],
      "source": [
        "import lamini\n",
        "lamini.api_key = \"712366712c83da4dcb7ef363156c9f7aa5d6bed985f7db02982aba5c5aa27cdf\"\n",
        "llm = lamini.Lamini(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
        "print(llm.generate(\n",
        "  prompt_template\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9ZpTFdP7xOh"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "import gradio as gr\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p_OVQPW8aCk"
      },
      "outputs": [],
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLRqagZ6sHSJ"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "    SYSTEM PROMPT: you are a prompt classifier , given this criteria debug the given prompt into:\n",
        "    \"text_to_text_coding\": \"These prompts are instructions or questions that involve writing or transforming code. They often include specific programming languages, functions, or algorithms. Example: 'Write a Python function to reverse a string.'\",\n",
        "    \"text_to_text_debugging\": \"These prompts are related to identifying and fixing errors in code. They often ask for debugging or troubleshooting steps. Example: 'Debug the following JavaScript code snippet that is causing a runtime error.\",\n",
        "    \"text_to_text_qa\": \"These prompts involve answering questions based on given text or general knowledge. They typically require concise, factual responses. Example: 'What is the capital of France?, this usually involve a document or textual input files such as pdf,docx,odt,scraped html,markdowns,data connectors to some databases or spreadsheets\",\n",
        "    \"text_to_text_conversation\": \"These prompts are for casual or structured conversation. They may include greetings, personal questions, or discussion topics. Example: 'How was your day?'\",\n",
        "    \"image_to_text_description\": \"you know it directly if any modality such as pictures or images or illustrations or photos visualisations has been inputted from and demanded to do something with it in a creative way or descriptive one or precise finding for somethings within it then prioritise this workflow of text to image over text to text qa , now These prompts ask for a textual description of an image, you directly know it if the input file is a given image or a picture which the prompts demand to caption it, you know that if the prompt seems to hav inputted image before hand and asks you to do something with it. They often require identifying objects, actions, or scenes in the image. Example: 'Describe the scene in this photo of a beach.' and These prompts involve generating creative or analytical text based on an image. Outputs can include stories, poems, character profiles, art critiques, and more. Example: 'Inspired by this photo, write a short story about a mischievous kitten playing with a ball of yarn.' Criteria include creative output, analytical output, detailed description, mood/emotion, and specific characters or settings.\",\n",
        "    \"image_to_text_object_finding\": \"you know it directly if any modality such by pictures or images or illustrations or photos visualisations has been inputted from and demanded to do something with it in a creative way or descriptive one or precise finding for somethings within it then prioritise this workflow of text to image over text to text qa, now These prompts involve identifying and describing specific objects or elements within an image. Outputs are factual and descriptive. Example: 'Identify all the animals in this image.' Criteria include object identification, detailed description, categorization, specific focus, and factual output.\"\n",
        "    \"image_to_text_ocr\": \"These prompts involve extracting text from an image using Optical Character Recognition (OCR). They typically require the exact text present in the image. Example: 'Extract the text from this scanned document.'\",\n",
        "    \"text_to_audio_speech\": \"These prompts are for converting text into spoken words, typically using text-to-speech technology. They usually specify the language and sometimes the tone or style of speech. Example: 'Convert this text to speech in English.'\",\n",
        "    \"text_to_audio_sound\": \"These prompts involve generating non-speech sounds from text descriptions, such as sound effects or music. Example: 'Generate the sound of rain falling.'\",\n",
        "    \"audio_to_text_sound_description\": \"These prompts ask for a description of the sounds heard in an audio clip. They often require identifying and describing the sound characteristics. Example: 'Describe the sounds in this audio clip of a forest.'\",\n",
        "    \"audio_to_text_speech_transcription\": \"These prompts involve transcribing spoken words from an audio clip into text. They typically require accurate representation of the speech. Example: 'Transcribe the speech in this interview recording.'\",\n",
        "    \"text_to_image_generation\": \"These prompts instruct generating an image based on a textual description. They often specify details about the scene, objects, or style. Example: 'Generate an image of a futuristic cityscape.'\",\n",
        "    \"text_to_image_generation\": '''\n",
        "When crafting prompts for Stable Diffusion, traditional narrative-style descriptions are less effective. Instead, use comma-separated keywords to provide specific visual cues. Break down the scene into individual components such as character, camera focus, lighting, colors, style, and additional elements for the best results.\n",
        "### Key Techniques:\n",
        "1. **Break it down and use keywords**:\n",
        "    - Example: \"a Mysterious figure, standing, in a moonlit forest, fog, blue hues, impressionist style, focus on silhouette, dramatic lighting, sharp details, photorealistic, ultra hd, 8k\"\n",
        "\n",
        "2. **Experiment with Styles and Perspectives**:\n",
        "    - **Styles**: Realistic, Abstract, Impressionistic, Cartoon/Comic/Manga/Anime, Minimalistic\n",
        "    - **Perspectives**: Bird’s Eye View, First-Person Perspective, Macro Perspective, Wide-Angle Perspective, Over-the-Shoulder Perspective\n",
        "\n",
        "3. **Incorporate Story Elements**: Include elements that imply a story without explicitly narrating it.\n",
        "\n",
        "4. **Ditch the Narration, Dial-up the Imagery**: Use keywords that evoke imagination (e.g., \"Dragon, mountain\").\n",
        "\n",
        "5. **Infuse Emotion into the Palette**: Use emotional and color-based descriptions (e.g., \"serenely mysterious,\" \"joyously enigmatic\").\n",
        "\n",
        "6. **A ‘NO’ goes a long way**: Utilize negative prompts to exclude unwanted elements (e.g., \"no humans\").\n",
        "\n",
        "7. **Emphasize with Brackets for Artistic Impact**: Use round brackets to emphasize important details (e.g., \"(mystical) scene with a (shining) unicorn\").\n",
        "\n",
        "8. **Negative Embeddings**: Use embeddings to steer the model away from specific traits (e.g., \"BadHands\" to avoid deformed hands).\n",
        "\n",
        "### Example Prompt:\n",
        "\"masterpiece, top quality, best quality, extreme detailed, highest detailed, official art, beautiful and aesthetic:1.2, colorful, beautiful face, solo, 1girl, in space, spacecraft, spacesuit, sun rays, indoors, wires and cables:1.1, science fiction:1.2, porthole, illuminator, stars, fantasy, high contrast, ink strokes, explosions, over exposure, purple and red tone impression, abstract, watercolor painting by John Berkey and Jeremy Mann, brush strokes, negative space\",\n",
        "    \"text_image_editing_inpainting\": \"These prompts are for editing an image by filling in missing parts based on a textual description. Example: 'Inpaint the missing part of this photo to restore the damaged area.'\",\n",
        "    \"text_image_editing_outpainting\": \"These prompts involve extending an image beyond its original boundaries based on a textual description. Example: 'Outpaint the edges of this image to expand the landscape.'\",\n",
        "    \"text_image_upscaling\": \"These prompts are for increasing the resolution of an image while preserving details, often specified by the desired resolution. Example: 'Upscale this image to 4K resolution.'\",\n",
        "    \"text_image_resolution_fixing\": \"These prompts involve enhancing an image's resolution and quality, often specified by correcting blurriness or artifacts. Example: 'Enhance the resolution of this low-quality image.'\"\n",
        "    \"text_to_audio_music\": \"These prompts involve generating music based on text descriptions. They often specify genres, artists, vocal characteristics, and moods. Example: 'k-pop, girl group, female vocalists, jersey club, liquid drum & bass, nocturnal'. Criteria include genre, artist/influence, vocal characteristics, mood/emotion, sub-genres/styles, and additional descriptors.\",\n",
        "    \"text_to_audio_sound_effects\": \"These prompts involve generating non-musical sounds based on text descriptions. They often specify environmental sounds, sound effects, or specific auditory scenarios. Example: 'Generate the sound of rain falling.' Criteria include sound type, specific sounds, setting/scenario, detailed descriptors, and mood/atmosphere.\"\n",
        "'''\n",
        "INPUT:\n",
        "`{prompt}`\n",
        "YOUR OUTPUT SHOULD BE IN JSON FORMAT LIKE with the following keys-values:\n",
        "OUTPUT:\n",
        "  \"classification\":<your-classification>,\n",
        "  \"prediction_confidence\":<your-confidence-rate-from-0-to-1>\n",
        "  \"explanation\":<your-expalantion>\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "answer what modality is given as input and the resulting output modality within this prompt based on the context in this format:\n",
        "input:<image> or <text> or <video> or <audio> or <None>\n",
        "output:<image> or <text> or <video> or <audio> or <None>\n",
        "prompt:{prompt}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4i9irVc8Eqf"
      },
      "outputs": [],
      "source": [
        "prompt_classification_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-pro\",\n",
        "        temperature=0\n",
        "    ),\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YsHyxPk-Anv",
        "outputId": "56afba72-3704-456d-e3bc-463137b87cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "place your promptgive me three meme caption options for this picture. The wackier, the better!\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "answer what modality is given as input and the resulting output modality within this prompt based on the context in this format:\n",
            "input:<image> or <text> or <video> or <audio> or <None>\n",
            "output:<image> or <text> or <video> or <audio> or <None>\n",
            "prompt:give me three meme caption options for this picture. The wackier, the better!\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "resopnse = prompt_classification_chain.invoke({\n",
        "    \"prompt\": input(\"place your prompt\")\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YL_NTtg-pNT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "reoSBUIm-vdr",
        "outputId": "8f8ae732-e029-44bf-ad49-f1ee21287d74"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "input:<image>\n",
              "output:<text>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(resopnse['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNLtcMAD07TO"
      },
      "outputs": [],
      "source": [
        "[\n",
        "  \"Drake: HipHop, Trap, male vocals\",\n",
        "  \"Bruno Mars: Funk, Dance Pop, Groovy, male vocals\",\n",
        "  \"Fleetwood Mac: Classic Rock, Mellifluous\",\n",
        "  \"Ed Sheeran: Folk, Acoustic Guitar, male vocals\",\n",
        "  \"Tim McGraw: Country, Americana, male vocals\",\n",
        "  \"Elton John: Piano Pop Rock, Theatrical, male vocals\",\n",
        "  \"Dolly Parton: Country, Storytelling, female vocals\",\n",
        "  \"Red Hot Chili Peppers: Funk Rock, Stadium, heavy drums\",\n",
        "  \"Coldplay: Alternative Rock, Atmospheric\",\n",
        "  \"Taylor Swift: Pop, Alternative Folk, Emotional, female vocals\",\n",
        "  \"Elvis Presley: 50s Rock, Hero Theme, male vocals\",\n",
        "  \"Adele: Soul, Emotional, Torch-Lounge, female vocals\",\n",
        "  \"Ariana Grande: Pop, Dance Pop, Ethereal, female vocals\",\n",
        "  \"Billie Eilish: Pop, Dark, Minimal, female vocals\",\n",
        "  \"The Weeknd: RnB, Dark, Cinematic, male vocals\",\n",
        "  \"Beyoncé: RnB, Anthemic, Danceable, female vocals\",\n",
        "  \"Kendrick Lamar: HipHop, Lyrical, Storytelling, male vocals\",\n",
        "  \"Lady Gaga: Pop, Theatrical, Dance, female vocals\",\n",
        "  \"Jay-Z: HipHop, Aggressive, Storytelling, male vocals\",\n",
        "  \"Rihanna: RnB, Dance Pop, Festive, female vocals\",\n",
        "  \"Kanye West: HipHop, Progressive, Eclectic, male vocals\",\n",
        "  \"Justin Bieber: Pop, Danceable, Chillwave, male vocals\",\n",
        "  \"Katy Perry: Pop, Glitter, Festive, female vocals\",\n",
        "  \"Snoop Dogg: Rap, Funk, Chill, male vocals\",\n",
        "  \"Metallica: Heavy Metal, Power\",\n",
        "  \"AC/DC: Hard Rock, Stomp\",\n",
        "  \"Madonna: Dance Pop, High-NRG, female vocals\",\n",
        "  \"David Bowie: 70s British Rock, Art, Eclectic, male vocals\",\n",
        "  \"Bob Dylan: Folk, Storytelling, Acoustic Guitar, male vocals\",\n",
        "  \"Post Malone: Rap, Ethereal, Ambient, male vocals\",\n",
        "  \"Maroon 5: Pop Rock, Danceable, male vocals\",\n",
        "  \"Shakira: Latin, Dance Pop, Festive, female vocals\",\n",
        "  \"Dua Lipa: Disco, Dance Pop, Groovy, female vocals\",\n",
        "  \"Michael Jackson: 80s Pop, Dance, Iconic, male vocals\",\n",
        "  \"Prince: Funk, Eclectic, Glam, male vocals\",\n",
        "  \"Miley Cyrus: Pop, Rock, Party, female vocals\",\n",
        "  \"Cardi B: Rap, Aggressive, Party, female vocals\",\n",
        "  \"Imagine Dragons: Rock, Anthemic, Emotion\",\n",
        "  \"Camila Cabello: Pop, Latin Jazz, Festive, female vocals\",\n",
        "  \"Harry Styles: Pop, Rock, Groovy, male vocals\",\n",
        "  \"Sam Smith: Soul, Emotional, Lounge, male vocals\",\n",
        "  \"Lizzo: Pop, Funk, Empowering, female vocals\",\n",
        "  \"Daft Punk: Electronic, Dance, Futuristic\",\n",
        "  \"Gorillaz: Alternative Rock, Electronic, Unusual\",\n",
        "  \"The Beatles: 60s British Pop, Classic, Rock\",\n",
        "  \"Queen: Rock, Operatic, Theatrical, Male Vocals\",\n",
        "  \"Led Zeppelin: Hard Rock, Blues Rock, Epic\",\n",
        "  \"Pink Floyd: Rock, Progressive, Atmospheric\",\n",
        "  \"The Rolling Stones: Rock, Blues Rock, Classic\",\n",
        "  \"Bob Marley: Reggae, Peaceful, Soulful, male vocals\",\n",
        "  \"Frank Sinatra: 1940s big band, Lounge Singer, male vocals\",\n",
        "  \"Aretha Franklin: Soul, Gospel, Powerful, female vocals\",\n",
        "  \"Whitney Houston: Pop, RnB, Emotional, female vocals\",\n",
        "  \"Stevie Wonder: Soul, Funk, Joyful, male vocals\",\n",
        "  \"The Chainsmokers: EDM, Dance, Party\",\n",
        "  \"Nicki Minaj: Rap, Danceable, Bold, female vocals\",\n",
        "  \"Green Day: Punk Rock, Aggressive, Youthful\",\n",
        "  \"Nirvana: Grunge, Dark, Raw, Male Vocals\",\n",
        "  \"Amy Winehouse: Soul, Jazz, Torch-Lounge, female vocals\",\n",
        "  \"Linkin Park: Rock, Nu Metal, Emotional\",\n",
        "  \"Aerosmith: Rock, Hard Rock, Classic\",\n",
        "  \"Bon Jovi: Rock, Anthem, Stadium\",\n",
        "  \"Billy Joel: Pop, Rock, Storytelling, male vocals\",\n",
        "  \"Phil Collins: Pop, Rock, Emotional, soundtrack, male vocals\",\n",
        "  \"Genesis: Rock, Progressive, Art\",\n",
        "  \"The Eagles: Rock, Country Rock, Harmonious\",\n",
        "  \"The Doors: Rock, Psychedelic, Mysterious\",\n",
        "  \"Janis Joplin: Rock, Blues Rock, Raw Emotion, female vocals\",\n",
        "  \"Jimi Hendrix: Rock, Psychedelic, Guitar Virtuoso, male vocals\",\n",
        "  \"The Who: Rock, Hard Rock, Theatrical\",\n",
        "  \"Black Sabbath: Heavy Metal, Doom\",\n",
        "  \"Iron Maiden: Heavy Metal, Epic, Theatrical\",\n",
        "  \"Judas Priest: Heavy Metal, Power, Leather\",\n",
        "  \"Motorhead: Heavy Metal, Rock’n’Roll, Aggressive\",\n",
        "  \"Slayer: Thrash Metal, Aggressive, Dark\",\n",
        "  \"Ozzy Osbourne: Heavy Metal, Dark, Theatrical, male vocals\",\n",
        "  \"Skrillex: Dubstep, Electronic, Intense, male vocals\",\n",
        "  \"Calvin Harris: EDM, Dance, Festive, male vocals\",\n",
        "  \"Avicii: EDM, Melodic, Euphoric, male vocals\",\n",
        "  \"Arctic Monkeys: Indie Rock, Garage, Cool\",\n",
        "  \"Tame Impala: Psychedelic Rock, Dreamy, Mellifluous\",\n",
        "  \"The Strokes: Indie Rock, Cool, Raw\",\n",
        "  \"Vampire Weekend: Indie Rock, Eclectic, Upbeat\",\n",
        "  \"Kings of Leon: Rock, Emotional, Raw\",\n",
        "  \"The Killers: Rock, Synthpop, Anthemic, male vocals\",\n",
        "  \"System of a Down: Metal, Political, Eccentric\",\n",
        "  \"Radiohead: Alternative Rock, Experimental, Atmospheric\",\n",
        "  \"Foo Fighters: Rock, Alternative, Energetic\",\n",
        "  \"Muse: Rock, Progressive, Theatrical\",\n",
        "  \"Tool: Progressive Metal, Dark, Complex\",\n",
        "  \"Rage Against the Machine: Rap Metal, Political, Aggressive\",\n",
        "  \"Pearl Jam: Grunge, Rock, Emotional\",\n",
        "  \"Soundgarden: 90s Grunge, Heavy, Dark\",\n",
        "  \"Alice in Chains: Grunge, Dark, Melodic\",\n",
        "  \"Sigur Rós: Post-Rock, Ethereal, Atmospheric, Icelandic\",\n",
        "  \"Björk: Alternative, Experimental, Unusual, female vocals\",\n",
        "  \"Enya: New Age, Ethereal, Calm, female vocals\",\n",
        "  \"Deadmau5: Electronic, House, Progressive\",\n",
        "  \"Marshmello: EDM, Dance, Happy\",\n",
        "  \"Zedd: EDM, Dance Pop, Energetic, male vocals\",\n",
        "  \"The XX: Indie Pop, Minimal, Atmospheric\",\n",
        "  \"Lana Del Rey: Pop, Sadcore, Cinematic, female vocals\",\n",
        "  \"Kacey Musgraves: Country, Pop, Mellifluous, female vocals\",\n",
        "  \"St. Vincent: Art Rock, Eclectic, Unusual, female vocals\",\n",
        "  \"Childish Gambino: HipHop, Funk, Thoughtful, male vocals\",\n",
        "  \"SZA: RnB, Neo Soul, Emotional, female vocals\",\n",
        "  \"Frank Ocean: RnB, Soulful, Introspective, male vocals\",\n",
        "  \"Tyler, The Creator: HipHop, Eclectic, Unusual, male vocals\",\n",
        "  \"Solange: RnB, Soul, Artistic, female vocals\",\n",
        "  \"Brockhampton: HipHop, Alternative, Collective\",\n",
        "  \"Janelle Monáe: Funk, RnB, Sci-Fi, female vocals\",\n",
        "  \"Mac DeMarco: Indie Pop, Slacker Rock, Chill, male vocals\",\n",
        "  \"Rufus Du Sol: Electronic, Dance, Atmospheric\",\n",
        "  \"Bon Iver: Indie Folk, Ethereal, Intimate, male vocals\",\n",
        "  \"Florence + The Machine: Indie Rock, Dramatic, Ethereal\",\n",
        "  \"Jack White: Rock, Blues, Raw, male vocals\",\n",
        "  \"Gary Clark Jr.: Blues Rock, Soulful, Gritty, male vocals\",\n",
        "  \"Leon Bridges: Soul, RnB, Retro, male vocals\",\n",
        "  \"Brittany Howard: Rock, Soul, Powerful, female vocals\",\n",
        "  \"Alabama Shakes: Rock, Blues Rock, Soulful\",\n",
        "  \"Glass Animals: Psychedelic Pop, Groovy, Eclectic\",\n",
        "  \"Portugal, The Man: Alternative Rock, Psychedelic, Catchy\",\n",
        "  \"FKA Twigs: RnB, Electronic, Avant-Garde, female vocals\",\n",
        "  \"The National: Indie Rock, Melancholy, Introspective\",\n",
        "  \"MGMT: Psychedelic Pop, Electronic, Playful\",\n",
        "  \"Empire of the Sun: Electronic, Pop, Theatrical\",\n",
        "  \"Grimes: Art Pop, Electronic, Experimental, female vocals\",\n",
        "  \"James Blake: Electronic, Soul, Minimalist, male vocals\",\n",
        "  \"The War on Drugs: Indie Rock, Heartland Rock, Melodic\",\n",
        "  \"Sufjan Stevens: Indie Folk, Baroque Pop, Intimate, male vocals\",\n",
        "  \"Bonobo: Downtempo, Electronic, Ambient\",\n",
        "  \"Caribou: Electronic, Psychedelic, Dance\",\n",
        "  \"Four Tet: Electronic, Ambient, Textural\",\n",
        "  \"Jamie xx: Electronic, House, Minimal\",\n",
        "  \"Nicolas Jaar: Electronic, Experimental, Atmospheric, male vocals\",\n",
        "  \"Flying Lotus: Electronic, Experimental HipHop, Fusion, male vocals\",\n",
        "  \"Thundercat: Funk, Jazz, Experimental, male vocals\",\n",
        "  \"Kamasi Washington: Jazz, Fusion, Epic, male vocals\",\n",
        "  \"Massive Attack: Trip Hop, Dark, Atmospheric\",\n",
        "  \"Portishead: Trip Hop, Dark, Cinematic\",\n",
        "  \"Aphex Twin: IDM, Electronic, Experimental, male vocals\",\n",
        "  \"Boards of Canada: IDM, Downtempo, Nostalgic\",\n",
        "  \"Burial: Dubstep, Ambient, Mysterious\",\n",
        "  \"J Dilla: HipHop, Soulful, Experimental, male vocals\",\n",
        "  \"MF DOOM: HipHop, Abstract, Lyrical, male vocals\",\n",
        "  \"Kendrick Lamar: HipHop, Conscious, Lyrical, male vocals\",\n",
        "  \"Blink-182: emo pop rock, male vocals\",\n",
        "  \"Green Day: Punk Rock, Aggressive, Youthful\",\n",
        "  \"Phoebe Bridgers: Bedroom, grungegaze, catchy, psychedelic, acoustic tape recording, female vocals\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L085tn1CsYTr"
      },
      "source": [
        "### classification code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhEOEtA7tTb6"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate -U\n",
        "!pip install -q transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "COxyPpGpsaOo",
        "outputId": "a248ac81-c972-4c1f-97ad-60cdff1f292a"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate -U  # Ensure accelerate is installed and updated in this environment\n",
        "import json\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "# ... (rest of your code remains the same)\n",
        "\n",
        "\n",
        "def load_dataset(json_data):\n",
        "    dataset = json.loads(json_data)\n",
        "    train_data = []\n",
        "    for item in dataset:\n",
        "        class_name = item[\"class_name\"]\n",
        "        for example in item[\"examples\"]:\n",
        "            train_data.append({\"text\": example, \"label\": class_name})\n",
        "    return train_data\n",
        "\n",
        "\n",
        "def prepare_data(train_data):\n",
        "    train_texts = [example[\"text\"] for example in train_data]\n",
        "    train_labels = [example[\"label\"] for example in train_data]\n",
        "    # Use stratify to ensure all classes are represented in both splits\n",
        "    # Adjust test_size to be at least the number of classes divided by the dataset size\n",
        "    test_size = max(0.2, len(set(train_labels)) / len(train_labels))\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        train_texts, train_labels, test_size=test_size, stratify=train_labels\n",
        "    )\n",
        "\n",
        "    label2id = {label: idx for idx, label in enumerate(set(train_labels))}\n",
        "    id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "    train_labels = [label2id[label] for label in train_labels]\n",
        "    val_labels = [label2id[label] for label in val_labels]\n",
        "\n",
        "    return train_texts, val_texts, train_labels, val_labels, label2id, id2label\n",
        "\n",
        "\n",
        "def tokenize_data(tokenizer, train_texts, val_texts):\n",
        "    train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "    val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "    return train_encodings, val_encodings\n",
        "\n",
        "\n",
        "class PromptDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def create_datasets(train_encodings, val_encodings, train_labels, val_labels):\n",
        "    train_dataset = PromptDataset(train_encodings, train_labels)\n",
        "    val_dataset = PromptDataset(val_encodings, val_labels)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "def train_model(train_dataset, val_dataset):\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=10,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    return model, trainer\n",
        "\n",
        "\n",
        "def evaluate_model(trainer):\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"Validation Loss: {eval_results['eval_loss']}\")\n",
        "    if \"eval_accuracy\" in eval_results:\n",
        "        print(f\"Validation Accuracy: {eval_results['eval_accuracy']}\")\n",
        "    else:\n",
        "        print(\"Validation Accuracy metric not found in evaluation results.\")\n",
        "\n",
        "\n",
        "def classify_prompt(model, tokenizer, id2label, prompt):\n",
        "    encodings = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**encodings)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "    return id2label[predicted_class_id]\n",
        "\n",
        "\n",
        "def main():\n",
        "    json_data = \"\"\"\n",
        "[\n",
        "    {\"class_name\":\"text_to_text_coding\", \"examples\":[\"Write a Python function to reverse a string. Another\", \"Implement the quicksort algorithm in Java.\"]},\n",
        "    {\"class_name\":\"text_to_text_debugging\", \"examples\":[\"Find the bug in this JavaScript code: `function add(a, b) { return a - b; }`. Another\", \"Debug this Python code to fix the IndexError.\"]},\n",
        "    {\"class_name\":\"text_to_text_qa\", \"examples\":[\"What is the capital of France? Another\", \"Explain the theory of relativity.\"]},\n",
        "    {\"class_name\":\"text_to_text_chat\", \"examples\":[\"How was your day? Another\", \"What are your plans for the weekend?\"]},\n",
        "    {\"class_name\":\"image_to_text_description\", \"examples\":[\"Describe the content of this image, including any objects and activities shown. Another\", \"What is happening in this photo?\"]},\n",
        "    {\"class_name\":\"image_to_text_ocr\", \"examples\":[\"Extract the text from this image. Another\", \"Identify and transcribe the text on this sign.\"]},\n",
        "    {\"class_name\":\"text_to_audio_speech\", \"examples\":[\"Convert this text to speech: 'Hello, how are you?'. Another\", \"Generate a speech audio for this paragraph about climate change.\"]},\n",
        "    {\"class_name\":\"text_to_audio_sound\", \"examples\":[\"Generate a sound of a cat meowing. Another\", \"Create a sound effect of thunder.\"]},\n",
        "    {\"class_name\":\"audio_to_text_sound_description\", \"examples\":[\"Listen to this audio and describe the sound. Another\", \"What animal sounds can you hear in this clip?\"]},\n",
        "    {\"class_name\":\"audio_to_text_speech_transcription\", \"examples\":[\"Transcribe this speech audio to text. Another\", \"Write down the dialogue from this audio recording.\"]},\n",
        "    {\"class_name\":\"text_to_image_generation\", \"examples\":[\"Generate an image of a sunset over the mountains. Another\", \"Create an illustration of a futuristic city.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_generation\", \"examples\":[\"Generate an image based on this base image with additional elements. Another\", \"Add a rainbow to this landscape image.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_inpainting\", \"examples\":[\"Edit this image to remove the object in the center. Another\", \"Fill in the missing parts of this damaged photo.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_outpainting\", \"examples\":[\"Extend the background of this image. Another\", \"Add more scenery to the edges of this photo.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_upscaling\", \"examples\":[\"Increase the resolution of this image. Another\", \"Upscale this low-resolution photo to make it clearer.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_resolution_fix\", \"examples\":[\"Improve the resolution quality of this image. Another\", \"Fix the resolution of this blurry picture.\"]}\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "    # Load dataset\n",
        "    train_data = load_dataset(json_data)\n",
        "\n",
        "    # Prepare data\n",
        "    train_texts, val_texts, train_labels, val_labels, label2id, id2label = prepare_data(\n",
        "        train_data\n",
        "    )\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Tokenize data\n",
        "    train_encodings, val_encodings = tokenize_data(tokenizer, train_texts, val_texts)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset, val_dataset = create_datasets(\n",
        "        train_encodings, val_encodings, train_labels, val_labels\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    model, trainer = train_model(train_dataset, val_dataset)\n",
        "\n",
        "    # Evaluate model\n",
        "    evaluate_model(trainer)\n",
        "\n",
        "    # Classify a new prompt\n",
        "    test_prompt = \"Give a brief description of this image.\"\n",
        "    predicted_class = classify_prompt(model, tokenizer, id2label, test_prompt)\n",
        "    print(f\"The predicted class for the prompt '{test_prompt}' is: {predicted_class}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One Level Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Le-PKrwGvXus"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SZUiSyXJvoWZ"
      },
      "outputs": [],
      "source": [
        "json_data = \"\"\"\n",
        "[\n",
        "    {\"class_name\":\"text_to_text_coding\", \"examples\":[\"Write a Python function to reverse a string.\", \"Implement the quicksort algorithm in Java.\"]},\n",
        "    {\"class_name\":\"text_to_text_debugging\", \"examples\":[\"Find the bug in this JavaScript code: `function add(a, b) { return a - b; }`.\", \"Debug this Python code to fix the IndexError.\"]},\n",
        "    {\"class_name\":\"text_to_text_qa\", \"examples\":[\"What is the capital of France?\", \"Explain the theory of relativity.\"]},\n",
        "    {\"class_name\":\"text_to_text_chat\", \"examples\":[\"How was your day?\", \"What are your plans for the weekend?\"]},\n",
        "    {\"class_name\":\"image_to_text_description\", \"examples\":[\"Describe the content of this image, including any objects and activities shown.\", \"What is happening in this photo?\"]},\n",
        "    {\"class_name\":\"image_to_text_ocr\", \"examples\":[\"Extract the text from this image.\", \"Identify and transcribe the text on this sign.\"]},\n",
        "    {\"class_name\":\"text_to_audio_speech\", \"examples\":[\"Convert this text to speech: 'Hello, how are you?'.\", \"Generate a speech audio for this paragraph about climate change.\"]},\n",
        "    {\"class_name\":\"text_to_audio_sound\", \"examples\":[\"Generate a sound of a cat meowing.\", \"Create a sound effect of thunder.\"]},\n",
        "    {\"class_name\":\"audio_to_text_sound_description\", \"examples\":[\"Listen to this audio and describe the sound.\", \"What animal sounds can you hear in this clip?\"]},\n",
        "    {\"class_name\":\"audio_to_text_speech_transcription\", \"examples\":[\"Transcribe this speech audio to text.\", \"Write down the dialogue from this audio recording.\"]},\n",
        "    {\"class_name\":\"text_to_image_generation\", \"examples\":[\"Generate an image of a sunset over the mountains.\", \"Create an illustration of a futuristic city.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_generation\", \"examples\":[\"Generate an image based on this base image with additional elements.\", \"Add a rainbow to this landscape image.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_inpainting\", \"examples\":[\"Edit this image to remove the object in the center.\", \"Fill in the missing parts of this damaged photo.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_outpainting\", \"examples\":[\"Extend the background of this image.\", \"Add more scenery to the edges of this photo.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_upscaling\", \"examples\":[\"Increase the resolution of this image.\", \"Upscale this low-resolution photo to make it clearer.\"]},\n",
        "    {\"class_name\":\"text_image_to_image_resolution_fix\", \"examples\":[\"Improve the resolution quality of this image.\", \"Fix the resolution of this blurry picture.\"]}\n",
        "]\n",
        "\"\"\"\n",
        "# save it in a dataset.json file\n",
        "with open('dataset.json', 'w') as file:\n",
        "    json.dump(json.loads(json_data), file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HDMITvRVvcqZ"
      },
      "outputs": [],
      "source": [
        "# Load the JSON data\n",
        "with open('dataset.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for category in data:\n",
        "    class_name = category['class_name']\n",
        "    examples = category['examples']\n",
        "\n",
        "    X.extend(examples)\n",
        "    y.extend([class_name] * len(examples))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "Q5UipTNmv2-k",
        "outputId": "6095060b-7cb3-4504-db93-2a9320fdc267"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LinearSVC())"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the text data into TF-IDF features\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Create and train the classifier\n",
        "classifier = OneVsRestClassifier(LinearSVC())\n",
        "classifier.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyI9Wqguv-NQ",
        "outputId": "ef4ed49e-4c5a-44ac-9861-dc5077684883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "   audio_to_text_sound_description       0.00      0.00      0.00         1\n",
            "         image_to_text_description       0.00      0.00      0.00         2\n",
            "    text_image_to_image_generation       0.00      0.00      0.00         0\n",
            "    text_image_to_image_inpainting       0.00      0.00      0.00         1\n",
            "text_image_to_image_resolution_fix       0.00      0.00      0.00         1\n",
            "     text_image_to_image_upscaling       0.50      1.00      0.67         1\n",
            "               text_to_audio_sound       0.00      0.00      0.00         1\n",
            "              text_to_audio_speech       0.00      0.00      0.00         0\n",
            "          text_to_image_generation       0.00      0.00      0.00         0\n",
            "                   text_to_text_qa       0.00      0.00      0.00         0\n",
            "\n",
            "                          accuracy                           0.14         7\n",
            "                         macro avg       0.05      0.10      0.07         7\n",
            "                      weighted avg       0.07      0.14      0.10         7\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Jm8A0EQPwJNr"
      },
      "outputs": [],
      "source": [
        "def classify_prompt(prompt):\n",
        "    # Transform the prompt into TF-IDF features\n",
        "    prompt_tfidf = vectorizer.transform([prompt])\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = classifier.predict(prompt_tfidf)\n",
        "\n",
        "    return prediction[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mldzJv2uwMH6",
        "outputId": "6d7460cb-bf45-4f35-f25f-a330acfb6a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: 'Generate a photorealistic image of a cyberpunk city at night'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe this 2-hour long podcast about quantum physics'\n",
            "Classification: audio_to_text_speech_transcription\n",
            "\n",
            "Prompt: 'Write a Python script to implement a neural network from scratch'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the emotional content conveyed in this abstract painting'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this academic paper on climate change into an engaging audio presentation'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Create a sound effect of a spaceship landing on an alien planet'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Explain the symbolism in this medieval tapestry image'\n",
            "Classification: text_to_text_qa\n",
            "\n",
            "Prompt: 'Debug this complex C++ code that implements a Red-Black tree'\n",
            "Classification: text_to_text_debugging\n",
            "\n",
            "Prompt: 'Generate an image of a futuristic vehicle inspired by biomimicry'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe and translate this Spanish audio to English text'\n",
            "Classification: audio_to_text_speech_transcription\n",
            "\n",
            "Prompt: 'Write a chatbot script that can engage in philosophical debates'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the architectural features in this photo of a Gothic cathedral'\n",
            "Classification: text_image_to_image_inpainting\n",
            "\n",
            "Prompt: 'Convert this poem into a melancholic piano composition'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Generate ambient background noise for a rainforest environment'\n",
            "Classification: text_image_to_image_outpainting\n",
            "\n",
            "Prompt: 'Identify and list all the plant species visible in this botanical illustration'\n",
            "Classification: image_to_text_ocr\n",
            "\n",
            "Prompt: 'Create an image that combines elements of Surrealism and Art Nouveau'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe this handwritten letter from the 18th century'\n",
            "Classification: image_to_text_ocr\n",
            "\n",
            "Prompt: 'Write a recursive algorithm to solve the Tower of Hanoi problem'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the choreography in this video of a contemporary dance performance'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this short story into a dramatic audiobook narration'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Generate a realistic sound of a busy stock exchange trading floor'\n",
            "Classification: text_to_audio_sound\n",
            "\n",
            "Prompt: 'Create an image that visualizes the concept of quantum entanglement'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Extract and summarize the key points from this economics lecture audio'\n",
            "Classification: image_to_text_ocr\n",
            "\n",
            "Prompt: 'Write a regex pattern to validate complex email addresses'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the emotional expressions of people in this crowd photograph'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this technical manual into a series of instructional audio clips'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Generate a sound effect for a magical spell being cast'\n",
            "Classification: text_to_audio_sound\n",
            "\n",
            "Prompt: 'Create an image that represents the five stages of grief'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe and annotate this recording of bird calls in a forest'\n",
            "Classification: audio_to_text_speech_transcription\n",
            "\n",
            "Prompt: 'Write a function to balance a binary search tree in Java'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Analyze and describe the brush techniques used in this Impressionist painting'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this rap lyrics into a classical orchestral arrangement'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Generate ambient sounds for a sci-fi space station interior'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Create an image that blends Renaissance and Cubist art styles'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe this audio of overlapping conversations at a cocktail party'\n",
            "Classification: audio_to_text_speech_transcription\n",
            "\n",
            "Prompt: 'Implement a multi-threaded web scraper in Python'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the geological formations visible in this satellite image'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this children's story into a lively, character-voiced audiobook'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Generate sound effects for a virtual reality sword fighting game'\n",
            "Classification: text_to_audio_sound\n",
            "\n",
            "Prompt: 'Create an image visualizing the process of photosynthesis'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Extract and organize data from this recorded business meeting'\n",
            "Classification: image_to_text_ocr\n",
            "\n",
            "Prompt: 'Write an algorithm to solve the traveling salesman problem efficiently'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Analyze and describe the use of color in this abstract expressionist artwork'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this technical whitepaper into an engaging podcast script'\n",
            "Classification: text_to_audio_speech\n",
            "\n",
            "Prompt: 'Generate a soundscape representing the birth of the universe'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Create an image that represents the concept of artificial intelligence'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe and identify speakers in this political debate audio'\n",
            "Classification: image_to_text_ocr\n",
            "\n",
            "Prompt: 'Implement a neural network for sentiment analysis in TensorFlow'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the microscopic structures visible in this electron micrograph'\n",
            "Classification: audio_to_text_sound_description\n",
            "\n",
            "Prompt: 'Convert this Shakespearean sonnet into a modern rap style audio'\n",
            "Classification: text_to_audio_speech\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test examples\n",
        "test_prompts = [\n",
        "    \"Generate a photorealistic image of a cyberpunk city at night\",\n",
        "    \"Transcribe this 2-hour long podcast about quantum physics\",\n",
        "    \"Write a Python script to implement a neural network from scratch\",\n",
        "    \"Describe the emotional content conveyed in this abstract painting\",\n",
        "    \"Convert this academic paper on climate change into an engaging audio presentation\",\n",
        "    \"Create a sound effect of a spaceship landing on an alien planet\",\n",
        "    \"Explain the symbolism in this medieval tapestry image\",\n",
        "    \"Debug this complex C++ code that implements a Red-Black tree\",\n",
        "    \"Generate an image of a futuristic vehicle inspired by biomimicry\",\n",
        "    \"Transcribe and translate this Spanish audio to English text\",\n",
        "    \"Write a chatbot script that can engage in philosophical debates\",\n",
        "    \"Describe the architectural features in this photo of a Gothic cathedral\",\n",
        "    \"Convert this poem into a melancholic piano composition\",\n",
        "    \"Generate ambient background noise for a rainforest environment\",\n",
        "    \"Identify and list all the plant species visible in this botanical illustration\",\n",
        "    \"Create an image that combines elements of Surrealism and Art Nouveau\",\n",
        "    \"Transcribe this handwritten letter from the 18th century\",\n",
        "    \"Write a recursive algorithm to solve the Tower of Hanoi problem\",\n",
        "    \"Describe the choreography in this video of a contemporary dance performance\",\n",
        "    \"Convert this short story into a dramatic audiobook narration\",\n",
        "    \"Generate a realistic sound of a busy stock exchange trading floor\",\n",
        "    \"Create an image that visualizes the concept of quantum entanglement\",\n",
        "    \"Extract and summarize the key points from this economics lecture audio\",\n",
        "    \"Write a regex pattern to validate complex email addresses\",\n",
        "    \"Describe the emotional expressions of people in this crowd photograph\",\n",
        "    \"Convert this technical manual into a series of instructional audio clips\",\n",
        "    \"Generate a sound effect for a magical spell being cast\",\n",
        "    \"Create an image that represents the five stages of grief\",\n",
        "    \"Transcribe and annotate this recording of bird calls in a forest\",\n",
        "    \"Write a function to balance a binary search tree in Java\",\n",
        "    \"Analyze and describe the brush techniques used in this Impressionist painting\",\n",
        "    \"Convert this rap lyrics into a classical orchestral arrangement\",\n",
        "    \"Generate ambient sounds for a sci-fi space station interior\",\n",
        "    \"Create an image that blends Renaissance and Cubist art styles\",\n",
        "    \"Transcribe this audio of overlapping conversations at a cocktail party\",\n",
        "    \"Implement a multi-threaded web scraper in Python\",\n",
        "    \"Describe the geological formations visible in this satellite image\",\n",
        "    \"Convert this children's story into a lively, character-voiced audiobook\",\n",
        "    \"Generate sound effects for a virtual reality sword fighting game\",\n",
        "    \"Create an image visualizing the process of photosynthesis\",\n",
        "    \"Extract and organize data from this recorded business meeting\",\n",
        "    \"Write an algorithm to solve the traveling salesman problem efficiently\",\n",
        "    \"Analyze and describe the use of color in this abstract expressionist artwork\",\n",
        "    \"Convert this technical whitepaper into an engaging podcast script\",\n",
        "    \"Generate a soundscape representing the birth of the universe\",\n",
        "    \"Create an image that represents the concept of artificial intelligence\",\n",
        "    \"Transcribe and identify speakers in this political debate audio\",\n",
        "    \"Implement a neural network for sentiment analysis in TensorFlow\",\n",
        "    \"Describe the microscopic structures visible in this electron micrograph\",\n",
        "    \"Convert this Shakespearean sonnet into a modern rap style audio\"\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    classification = classify_prompt(prompt)\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Classification: {classification}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D95rgHGxgm7",
        "outputId": "8e8765ae-44ce-40e0-e877-04d16ed9ce28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: 'generate an image of photography, portrait of contrast, profile silhouette of a black man, vibrant orange backdrop, visualize using a camera setup that mimics a large aperture, focusing solely on the silhouette's edge, while a low ISO maintains the richness of color without grain, photorealistic, UHD --ar 9:16 --chaos 1. 7 --style raw'\n",
            "Classification: text_to_image_generation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = input(\"give your prompt:\\n\")\n",
        "classification = classify_prompt(prompt)\n",
        "\n",
        "print(f\"Prompt: '{prompt}'\")\n",
        "\n",
        "print(f\"Classification: {classification}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UCFE2mwEyzDg"
      },
      "outputs": [],
      "source": [
        "labeled_intricate_prompts = [\n",
        "    (\"Generate a hyper-realistic image of a dragon in flight over a medieval castle\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe and summarize this hour-long lecture on astrophysics\", \"audio_to_text_speech_transcription\"),\n",
        "    (\"Write a recursive Python function to solve the N-Queens problem\", \"text_to_text_coding\"),\n",
        "    (\"Describe the artistic techniques used in this Baroque painting\", \"image_to_text_description\"),\n",
        "    (\"Convert this research paper on neuroscience into an engaging podcast episode\", \"text_to_audio_speech\"),\n",
        "    (\"Create a complex sound effect for a time machine activating\", \"text_to_audio_sound\"),\n",
        "    (\"Analyze the composition and symbolism in this surrealist photograph\", \"image_to_text_description\"),\n",
        "    (\"Debug and optimize this multithreaded C++ code for matrix multiplication\", \"text_to_text_debugging\"),\n",
        "    (\"Generate an image blending Art Deco and Futurism styles\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe and translate this French audio interview to English\", \"audio_to_text_speech_transcription\"),\n",
        "    (\"Implement a chatbot that can discuss and analyze literary works\", \"text_to_text_coding\"),\n",
        "    (\"Describe the geological layers visible in this cross-section image\", \"image_to_text_description\"),\n",
        "    (\"Transform this jazz composition into a classical orchestral piece\", \"text_to_audio_speech\"),\n",
        "    (\"Generate ambient sounds for an underwater alien city\", \"text_to_audio_sound\"),\n",
        "    (\"Identify and explain the mathematical equations in this physics textbook page\", \"image_to_text_ocr\"),\n",
        "    (\"Create an image visualizing the concept of parallel universes\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe this old vinyl recording of a 1920s radio show\", \"audio_to_text_speech_transcription\"),\n",
        "    (\"Write an efficient algorithm for solving the knapsack problem\", \"text_to_text_coding\"),\n",
        "    (\"Describe the body language and facial expressions in this silent film scene\", \"image_to_text_description\"),\n",
        "    (\"Convert this epic poem into a dramatic audio performance with multiple voices\", \"text_to_audio_speech\"),\n",
        "    (\"Generate the sound of a steampunk factory in full operation\", \"text_to_audio_sound\"),\n",
        "    (\"Create an image representing the flow of time in Einstein's theory of relativity\", \"text_to_image_generation\"),\n",
        "    (\"Extract and analyze the key arguments from this political debate audio\", \"audio_to_text_speech_transcription\"),\n",
        "    (\"Implement a neural network for image classification using PyTorch\", \"text_to_text_coding\"),\n",
        "    (\"Describe the architectural elements and their functions in this blueprint\", \"image_to_text_description\"),\n",
        "    (\"Transform this academic lecture into an accessible audio guide for beginners\", \"text_to_audio_speech\"),\n",
        "    (\"Create a soundscape representing the evolution of life on Earth\", \"text_to_audio_sound\"),\n",
        "    (\"Generate an image that combines elements of Dadaism and Pop Art\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe and categorize the different animal sounds in this jungle recording\", \"audio_to_text_sound_description\"),\n",
        "    (\"Write a function to implement the A* pathfinding algorithm in JavaScript\", \"text_to_text_coding\"),\n",
        "    (\"Analyze and describe the use of perspective in this Renaissance painting\", \"image_to_text_description\"),\n",
        "    (\"Convert this technical manual into an interactive audio tutorial\", \"text_to_audio_speech\"),\n",
        "    (\"Generate a complex sound effect for a supernatural portal opening\", \"text_to_audio_sound\"),\n",
        "    (\"Create an image visualizing the structure of a black hole\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe and identify different musical instruments in this orchestral piece\", \"audio_to_text_sound_description\"),\n",
        "    (\"Implement a distributed system for big data processing using Apache Spark\", \"text_to_text_coding\"),\n",
        "    (\"Describe the cellular structures visible in this electron microscope image\", \"image_to_text_description\"),\n",
        "    (\"Transform this children's story into a full cast audio drama\", \"text_to_audio_speech\"),\n",
        "    (\"Generate the sound of an alien language being spoken\", \"text_to_audio_sound\"),\n",
        "    (\"Create an image representing the concept of quantum computing\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe and analyze the emotional content in this therapy session recording\", \"audio_to_text_speech_transcription\"),\n",
        "    (\"Write an algorithm to solve Sudoku puzzles efficiently\", \"text_to_text_coding\"),\n",
        "    (\"Describe the various ecosystems depicted in this nature documentary still\", \"image_to_text_description\"),\n",
        "    (\"Convert this scientific paper on climate change into an engaging audio presentation\", \"text_to_audio_speech\"),\n",
        "    (\"Generate a soundscape representing the birth and death of stars\", \"text_to_audio_sound\"),\n",
        "    (\"Create an image that visualizes the concept of machine learning\", \"text_to_image_generation\"),\n",
        "    (\"Transcribe and identify different accents in this multilingual conversation\", \"audio_to_text_speech_transcription\"),\n",
        "    (\"Implement a blockchain system with smart contracts using Solidity\", \"text_to_text_coding\"),\n",
        "    (\"Analyze and describe the symbolism in this allegorical painting\", \"image_to_text_description\"),\n",
        "    (\"Transform this technical whitepaper into an accessible audiobook for non-experts\", \"text_to_audio_speech\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v4bG9ehjy5As"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Fine-tuned Model:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "   audio_to_text_sound_description       0.00      0.00      0.00         1\n",
            "audio_to_text_speech_transcription       1.00      0.50      0.67         2\n",
            "         image_to_text_description       1.00      1.00      1.00         2\n",
            "   text_image_to_image_outpainting       0.00      0.00      0.00         1\n",
            "               text_to_audio_sound       1.00      0.50      0.67         2\n",
            "              text_to_audio_speech       1.00      0.50      0.67         2\n",
            "          text_to_image_generation       0.67      1.00      0.80         2\n",
            "               text_to_text_coding       0.25      1.00      0.40         1\n",
            "\n",
            "                          accuracy                           0.62        13\n",
            "                         macro avg       0.61      0.56      0.52        13\n",
            "                      weighted avg       0.74      0.62      0.62        13\n",
            "\n",
            "Prompt: 'Create an image of a futuristic cityscape'\n",
            "Classification: text_to_image_generation\n",
            "\n",
            "Prompt: 'Transcribe this audio file of a business meeting'\n",
            "Classification: audio_to_text_speech_transcription\n",
            "\n",
            "Prompt: 'Write a Python function to implement quicksort'\n",
            "Classification: text_to_text_coding\n",
            "\n",
            "Prompt: 'Describe the objects and their arrangement in this still life painting'\n",
            "Classification: image_to_text_description\n",
            "\n",
            "Prompt: 'Convert this essay into a narrated audio file'\n",
            "Classification: text_to_audio_speech\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def fine_tune_classifier(existing_classifier, existing_vectorizer, new_labeled_data):\n",
        "    # Unpack the new labeled data\n",
        "    new_X, new_y = zip(*new_labeled_data)\n",
        "\n",
        "    # Combine new data with existing data\n",
        "    X_combined = list(existing_classifier.classes_) + list(new_X)\n",
        "    y_combined = list(existing_classifier.classes_) + list(new_y)\n",
        "\n",
        "    # Re-fit the vectorizer with the combined data\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X_combined_tfidf = vectorizer.fit_transform(X_combined)\n",
        "\n",
        "    # Split the combined data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_combined_tfidf, y_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create and train a new classifier\n",
        "    new_classifier = OneVsRestClassifier(LinearSVC())\n",
        "    new_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the new classifier\n",
        "    y_pred = new_classifier.predict(X_test)\n",
        "    print(\"Classification Report for Fine-tuned Model:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return new_classifier, vectorizer\n",
        "\n",
        "# Function to classify new prompts\n",
        "def classify_prompt(classifier, vectorizer, prompt):\n",
        "    prompt_tfidf = vectorizer.transform([prompt])\n",
        "    prediction = classifier.predict(prompt_tfidf)\n",
        "    return prediction[0]\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'classifier' and 'vectorizer' are your existing classifier and vectorizer\n",
        "# And 'labeled_intricate_prompts' is the list of new labeled prompts we created earlier\n",
        "\n",
        "fine_tuned_classifier, fine_tuned_vectorizer = fine_tune_classifier(classifier, vectorizer, labeled_intricate_prompts)\n",
        "\n",
        "# Test the fine-tuned classifier\n",
        "test_prompts = [\n",
        "    \"Create an image of a futuristic cityscape\",\n",
        "    \"Transcribe this audio file of a business meeting\",\n",
        "    \"Write a Python function to implement quicksort\",\n",
        "    \"Describe the objects and their arrangement in this still life painting\",\n",
        "    \"Convert this essay into a narrated audio file\"\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    classification = classify_prompt(fine_tuned_classifier, fine_tuned_vectorizer, prompt)\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Classification: {classification}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: 'generate me a song named Frank Ocean, RnB, Soulful, Introspective, male vocals '\n",
            "Classification: text_to_audio_sound\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = input(\"give your prompt:\\n\")    \n",
        "classification = classify_prompt(fine_tuned_classifier, fine_tuned_vectorizer, prompt)\n",
        "print(f\"Prompt: '{prompt}'\")\n",
        "print(f\"Classification: {classification}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnsUIol9Kfwt"
      },
      "source": [
        "## TWO LEVEL CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbIkAyZcNaxs",
        "outputId": "af4da860-62f7-4516-9c0a-a02234a7512c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: 'Generate an image of a cat playing with a ball'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Convert this paragraph into speech'\n",
            "Modality: Text_To_Audio\n",
            "Task: Text_To_Speech\n",
            "\n",
            "Prompt: 'What is the capital of Spain?'\n",
            "Modality: Text_To_Text\n",
            "Task: Question_Answering\n",
            "\n",
            "Prompt: 'Describe the objects in this photograph'\n",
            "Modality: Image_To_Text\n",
            "Task: Object_Identification\n",
            "\n",
            "Prompt: 'Transcribe this audio file of a business meeting'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Global classifier for main modalities\n",
        "class GlobalClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.classifier = OneVsRestClassifier(LinearSVC())\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_tfidf = self.vectorizer.fit_transform(X)\n",
        "        self.classifier.fit(X_tfidf, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_tfidf = self.vectorizer.transform(X)\n",
        "        return self.classifier.predict(X_tfidf)\n",
        "\n",
        "# Sub-classifier for specific tasks within a modality\n",
        "class SubClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.classifier = OneVsRestClassifier(LinearSVC())\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_tfidf = self.vectorizer.fit_transform(X)\n",
        "        self.classifier.fit(X_tfidf, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_tfidf = self.vectorizer.transform(X)\n",
        "        return self.classifier.predict(X_tfidf)\n",
        "\n",
        "# Main classification pipeline\n",
        "class PromptClassifier:\n",
        "    def __init__(self):\n",
        "        self.global_classifier = GlobalClassifier()\n",
        "        self.sub_classifiers = {\n",
        "            \"Text_To_Image\": SubClassifier(),\n",
        "            \"Text_To_Video\": SubClassifier(),\n",
        "            \"Text_To_Audio\": SubClassifier(),\n",
        "            \"Text_To_Text\": SubClassifier(),\n",
        "            \"Image_To_Text\": SubClassifier(),\n",
        "            \"Video_To_Text\": SubClassifier(),\n",
        "            \"Audio_To_Text\": SubClassifier()\n",
        "        }\n",
        "\n",
        "    def train(self, data):\n",
        "        # Train global classifier\n",
        "        global_X, global_y = zip(*[(prompt, modality) for modality, tasks in data.items() for task, prompts in tasks.items() for prompt in prompts])\n",
        "        self.global_classifier.train(global_X, global_y)\n",
        "\n",
        "        # Train sub-classifiers\n",
        "        for modality, tasks in data.items():\n",
        "            sub_X, sub_y = zip(*[(prompt, task) for task, prompts in tasks.items() for prompt in prompts])\n",
        "            self.sub_classifiers[modality].train(sub_X, sub_y)\n",
        "\n",
        "    def classify(self, prompt):\n",
        "        # First level: Global classification\n",
        "        modality = self.global_classifier.predict([prompt])[0]\n",
        "\n",
        "        # Second level: Sub-classification\n",
        "        task = self.sub_classifiers[modality].predict([prompt])[0]\n",
        "\n",
        "        return modality, task\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample training data\n",
        "    data = {\n",
        "        \"Text_To_Image\": {\n",
        "            \"Image_Generation\": [\"Generate an image of a sunset\", \"Create a picture of a futuristic city\"],\n",
        "            \"Image_Editing\": [\"Remove the background from this image\", \"Adjust the color balance of this photo\"],\n",
        "            \"Image_Inpainting\": [\"Fill in the missing parts of this damaged photo\", \"Complete this partial image\"],\n",
        "            \"Image_Outpainting\": [\"Extend the edges of this image\", \"Add more scenery around this picture\"],\n",
        "            \"Image_Upscaling\": [\"Increase the resolution of this image\", \"Make this image larger and clearer\"],\n",
        "            \"Image_High_Resolution_Fix\": [\"Fix the pixelation in this low-res image\", \"Enhance the details of this blurry picture\"]\n",
        "        },\n",
        "        \"Text_To_Audio\": {\n",
        "            \"Text_To_Speech\": [\"Convert this text to spoken words\", \"Read this paragraph aloud\"],\n",
        "            \"Sound_Generation\": [\"Create the sound of ocean waves\", \"Generate a thunderstorm sound effect\"],\n",
        "            \"Music_Generation\": [\"Compose a classical piano piece\", \"Create a jazz melody\"]\n",
        "        },\n",
        "        \"Text_To_Text\": {\n",
        "            \"Question_Answering\": [\"What is the capital of France?\", \"How does photosynthesis work?\"],\n",
        "            \"Conversation_And_Role_Play\": [\"Pretend you're a medieval knight\", \"Let's have a conversation about climate change\"],\n",
        "            \"Summarization\": [\"Summarize this article about quantum computing\", \"Give me a brief overview of World War II\"],\n",
        "            \"Code_Generation\": [\"Write a Python function to sort a list\", \"Create a JavaScript class for a shopping cart\"],\n",
        "            \"Code_Debugging\": [\"Fix the bug in this C++ code\", \"What's wrong with this SQL query?\"]\n",
        "        },\n",
        "        \"Image_To_Text\": {\n",
        "            \"Image_Description\": [\"Describe what you see in this image\", \"What's happening in this picture?\"],\n",
        "            \"OCR_Text_Extraction\": [\"Extract the text from this sign\", \"Read the words in this document image\"],\n",
        "            \"Object_Identification\": [\"List the objects in this image\", \"What items can you see in this photo?\"],\n",
        "            \"Image_Palette_Extraction\": [\"What are the main colors in this image?\", \"Describe the color scheme of this picture\"],\n",
        "            \"People_Face_Recognition\": [\"Identify the people in this photo\", \"How many faces can you see in this image?\"],\n",
        "            \"Image_Prompt_Generation\": [\"Generate a prompt to recreate this image\", \"Describe this image in a way suitable for an image generation model\"]\n",
        "        },\n",
        "        \"Audio_To_Text\": {\n",
        "            \"Sound_Identification\": [\"What kind of sound is this?\", \"Identify the instruments in this audio clip\"],\n",
        "            \"Speech_Transcription\": [\"Transcribe this spoken audio to text\", \"Write down what is being said in this recording\"],\n",
        "            \"Music_Prompt_Generation\": [\"Describe this music in words\", \"Generate a text prompt to recreate this musical piece\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Initialize and train the classifier\n",
        "    classifier = PromptClassifier()\n",
        "    classifier.train(data)\n",
        "\n",
        "    # Test the classifier\n",
        "    test_prompts = [\n",
        "        \"Generate an image of a cat playing with a ball\",\n",
        "        \"Convert this paragraph into speech\",\n",
        "        \"What is the capital of Spain?\",\n",
        "        \"Describe the objects in this photograph\",\n",
        "        \"Transcribe this audio file of a business meeting\"\n",
        "    ]\n",
        "\n",
        "    for prompt in test_prompts:\n",
        "        modality, task = classifier.classify(prompt)\n",
        "        print(f\"Prompt: '{prompt}'\")\n",
        "        print(f\"Modality: {modality}\")\n",
        "        print(f\"Task: {task}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ye0bxq6kOhQD"
      },
      "outputs": [],
      "source": [
        "test_prompts = [\n",
        "    # Text-to-Image\n",
        "    \"Create a photorealistic image of a futuristic cityscape with flying cars and holographic billboards\",\n",
        "    \"Generate an oil painting style image of a serene lake surrounded by autumn trees at sunset\",\n",
        "    \"Design a logo for a tech startup that combines the concepts of AI and sustainability\",\n",
        "    \"Illustrate a scene from Alice in Wonderland in the style of Salvador Dali\",\n",
        "    \"Create an anatomically correct diagram of the human respiratory system\",\n",
        "    \"Generate a minimalist poster for a sci-fi movie about time travel\",\n",
        "    \"Produce a realistic 3D render of a new smartphone design\",\n",
        "    \"Create a detailed infographic about the water cycle\",\n",
        "    \"Generate a pixel art scene of a medieval castle under siege\",\n",
        "    \"Design a futuristic space vehicle capable of interstellar travel\",\n",
        "\n",
        "    # Text-to-Audio\n",
        "    \"Convert this Shakespeare sonnet into a dramatic reading with background music\",\n",
        "    \"Generate a soundscape that represents a busy metropolitan area during rush hour\",\n",
        "    \"Create a MIDI file of a jazz improvisation based on 'Autumn Leaves'\",\n",
        "    \"Produce a podcast intro with upbeat music and a voice-over\",\n",
        "    \"Generate the sound of a thunderstorm with heavy rain and distant lightning\",\n",
        "    \"Create a text-to-speech narration of this scientific paper with proper pronunciation of technical terms\",\n",
        "    \"Compose a 30-second jingle for a children's toy commercial\",\n",
        "    \"Generate ambient background noise for a coffee shop scene in a movie\",\n",
        "    \"Create a voiceover for this product demonstration video with a British accent\",\n",
        "    \"Produce a binaural audio experience of walking through a rainforest\",\n",
        "\n",
        "    # Text-to-Text\n",
        "    \"Summarize the key points of the latest IPCC report on climate change\",\n",
        "    \"Translate this legal document from English to Mandarin while preserving legal terminology\",\n",
        "    \"Write a Python script to implement a basic neural network from scratch\",\n",
        "    \"Compose a haiku about the changing seasons\",\n",
        "    \"Generate a detailed, step-by-step recipe for making authentic Italian risotto\",\n",
        "    \"Create a comprehensive literature review on the effects of social media on mental health\",\n",
        "    \"Write a press release announcing a breakthrough in quantum computing\",\n",
        "    \"Develop a chatbot script for handling customer service inquiries about product returns\",\n",
        "    \"Compose a formal email to schedule a business meeting with a potential investor\",\n",
        "    \"Write a detailed character profile for the protagonist of a cyberpunk novel\",\n",
        "\n",
        "    # Image-to-Text\n",
        "    \"Analyze this MRI scan and provide a detailed description of any abnormalities\",\n",
        "    \"Describe the architectural style and key features of this historic building\",\n",
        "    \"Identify and list all the species of flowers visible in this botanical photograph\",\n",
        "    \"Provide a detailed analysis of the brushwork and color palette used in this Impressionist painting\",\n",
        "    \"Extract and transcribe all text visible in this photograph of a city street\",\n",
        "    \"Describe the body language and emotions of the people in this group photograph\",\n",
        "    \"Analyze the composition and use of light in this black and white landscape photograph\",\n",
        "    \"Identify and describe the status of the chess game shown in this image\",\n",
        "    \"Provide a detailed description of the geological features visible in this satellite image\",\n",
        "    \"Analyze the nutritional content of the meal shown in this food photograph\",\n",
        "\n",
        "    # Audio-to-Text\n",
        "    \"Transcribe and identify the speakers in this recorded panel discussion\",\n",
        "    \"Analyze the emotional tone and sentiment in this political speech\",\n",
        "    \"Identify the instruments and describe the structure of this classical music piece\",\n",
        "    \"Transcribe the lyrics and identify the genre of this song\",\n",
        "    \"Provide a detailed description of the bird calls in this nature recording\",\n",
        "    \"Transcribe this audio file of a fast-paced sports commentary\",\n",
        "    \"Analyze the accent and dialect features in this recorded conversation\",\n",
        "    \"Identify and transcribe the sound effects used in this movie scene\",\n",
        "    \"Provide a time-stamped transcription of key points made in this lecture recording\",\n",
        "    \"Analyze the prosody and intonation patterns in this audiobook narration\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcWVgD-VOl6A",
        "outputId": "5d4ff91c-ad62-4565-d5ed-e55837178339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifying test prompts:\n",
            "Prompt: 'Create a photorealistic image of a futuristic cityscape with flying cars and holographic billboards'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Generate an oil painting style image of a serene lake surrounded by autumn trees at sunset'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Design a logo for a tech startup that combines the concepts of AI and sustainability'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Upscaling\n",
            "\n",
            "Prompt: 'Illustrate a scene from Alice in Wonderland in the style of Salvador Dali'\n",
            "Modality: Image_To_Text\n",
            "Task: OCR_Text_Extraction\n",
            "\n",
            "Prompt: 'Create an anatomically correct diagram of the human respiratory system'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Generate a minimalist poster for a sci-fi movie about time travel'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Produce a realistic 3D render of a new smartphone design'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Create a detailed infographic about the water cycle'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Generate a pixel art scene of a medieval castle under siege'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Design a futuristic space vehicle capable of interstellar travel'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Convert this Shakespeare sonnet into a dramatic reading with background music'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Editing\n",
            "\n",
            "Prompt: 'Generate a soundscape that represents a busy metropolitan area during rush hour'\n",
            "Modality: Text_To_Audio\n",
            "Task: Sound_Generation\n",
            "\n",
            "Prompt: 'Create a MIDI file of a jazz improvisation based on 'Autumn Leaves''\n",
            "Modality: Text_To_Audio\n",
            "Task: Music_Generation\n",
            "\n",
            "Prompt: 'Produce a podcast intro with upbeat music and a voice-over'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Debugging\n",
            "\n",
            "Prompt: 'Generate the sound of a thunderstorm with heavy rain and distant lightning'\n",
            "Modality: Text_To_Audio\n",
            "Task: Sound_Generation\n",
            "\n",
            "Prompt: 'Create a text-to-speech narration of this scientific paper with proper pronunciation of technical terms'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Compose a 30-second jingle for a children's toy commercial'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Generate ambient background noise for a coffee shop scene in a movie'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Create a voiceover for this product demonstration video with a British accent'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Produce a binaural audio experience of walking through a rainforest'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n",
            "Prompt: 'Summarize the key points of the latest IPCC report on climate change'\n",
            "Modality: Text_To_Text\n",
            "Task: Question_Answering\n",
            "\n",
            "Prompt: 'Translate this legal document from English to Mandarin while preserving legal terminology'\n",
            "Modality: Image_To_Text\n",
            "Task: OCR_Text_Extraction\n",
            "\n",
            "Prompt: 'Write a Python script to implement a basic neural network from scratch'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Compose a haiku about the changing seasons'\n",
            "Modality: Text_To_Text\n",
            "Task: Question_Answering\n",
            "\n",
            "Prompt: 'Generate a detailed, step-by-step recipe for making authentic Italian risotto'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Create a comprehensive literature review on the effects of social media on mental health'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Write a press release announcing a breakthrough in quantum computing'\n",
            "Modality: Text_To_Text\n",
            "Task: Summarization\n",
            "\n",
            "Prompt: 'Develop a chatbot script for handling customer service inquiries about product returns'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Compose a formal email to schedule a business meeting with a potential investor'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Write a detailed character profile for the protagonist of a cyberpunk novel'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Analyze this MRI scan and provide a detailed description of any abnormalities'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Upscaling\n",
            "\n",
            "Prompt: 'Describe the architectural style and key features of this historic building'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Upscaling\n",
            "\n",
            "Prompt: 'Identify and list all the species of flowers visible in this botanical photograph'\n",
            "Modality: Image_To_Text\n",
            "Task: People_Face_Recognition\n",
            "\n",
            "Prompt: 'Provide a detailed analysis of the brushwork and color palette used in this Impressionist painting'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Editing\n",
            "\n",
            "Prompt: 'Extract and transcribe all text visible in this photograph of a city street'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Describe the body language and emotions of the people in this group photograph'\n",
            "Modality: Image_To_Text\n",
            "Task: Image_Palette_Extraction\n",
            "\n",
            "Prompt: 'Analyze the composition and use of light in this black and white landscape photograph'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Upscaling\n",
            "\n",
            "Prompt: 'Identify and describe the status of the chess game shown in this image'\n",
            "Modality: Image_To_Text\n",
            "Task: Image_Palette_Extraction\n",
            "\n",
            "Prompt: 'Provide a detailed description of the geological features visible in this satellite image'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_High_Resolution_Fix\n",
            "\n",
            "Prompt: 'Analyze the nutritional content of the meal shown in this food photograph'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_High_Resolution_Fix\n",
            "\n",
            "Prompt: 'Transcribe and identify the speakers in this recorded panel discussion'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n",
            "Prompt: 'Analyze the emotional tone and sentiment in this political speech'\n",
            "Modality: Image_To_Text\n",
            "Task: OCR_Text_Extraction\n",
            "\n",
            "Prompt: 'Identify the instruments and describe the structure of this classical music piece'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n",
            "Prompt: 'Transcribe the lyrics and identify the genre of this song'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Upscaling\n",
            "\n",
            "Prompt: 'Provide a detailed description of the bird calls in this nature recording'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_High_Resolution_Fix\n",
            "\n",
            "Prompt: 'Transcribe this audio file of a fast-paced sports commentary'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n",
            "Prompt: 'Analyze the accent and dialect features in this recorded conversation'\n",
            "Modality: Image_To_Text\n",
            "Task: OCR_Text_Extraction\n",
            "\n",
            "Prompt: 'Identify and transcribe the sound effects used in this movie scene'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n",
            "Prompt: 'Provide a time-stamped transcription of key points made in this lecture recording'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n",
            "Prompt: 'Analyze the prosody and intonation patterns in this audiobook narration'\n",
            "Modality: Image_To_Text\n",
            "Task: OCR_Text_Extraction\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifying test prompts:\")\n",
        "for prompt in test_prompts:\n",
        "    modality, task = classifier.classify(prompt)\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Modality: {modality}\")\n",
        "    print(f\"Task: {task}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1d-L-eXNYKF"
      },
      "source": [
        "### after fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZJ9EshvKiwr",
        "outputId": "ecd0e9a6-f160-4f87-a34c-04a162595e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Evaluation:\n",
            "Global Classifier Performance:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Audio_To_Text       1.00      0.50      0.67         4\n",
            "Image_To_Text       0.80      1.00      0.89         4\n",
            "Text_To_Audio       1.00      1.00      1.00         4\n",
            "Text_To_Image       1.00      1.00      1.00         4\n",
            " Text_To_Text       0.80      1.00      0.89         4\n",
            "\n",
            "     accuracy                           0.90        20\n",
            "    macro avg       0.92      0.90      0.89        20\n",
            " weighted avg       0.92      0.90      0.89        20\n",
            "\n",
            "\n",
            "Sub-Classifier Performance:\n",
            "\n",
            "Image_To_Text:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  Image_Description       1.00      1.00      1.00         2\n",
            "OCR_Text_Extraction       1.00      1.00      1.00         2\n",
            "\n",
            "           accuracy                           1.00         4\n",
            "          macro avg       1.00      1.00      1.00         4\n",
            "       weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Text_To_Audio:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Sound_Generation       1.00      1.00      1.00         2\n",
            "  Text_To_Speech       1.00      1.00      1.00         2\n",
            "\n",
            "        accuracy                           1.00         4\n",
            "       macro avg       1.00      1.00      1.00         4\n",
            "    weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Text_To_Text:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Question_Answering       1.00      1.00      1.00         2\n",
            "     Summarization       1.00      1.00      1.00         2\n",
            "\n",
            "          accuracy                           1.00         4\n",
            "         macro avg       1.00      1.00      1.00         4\n",
            "      weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Audio_To_Text:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            " OCR_Text_Extraction       0.00      0.00      0.00         0\n",
            "  Question_Answering       0.00      0.00      0.00         0\n",
            "Sound_Identification       1.00      0.50      0.67         2\n",
            "Speech_Transcription       1.00      0.50      0.67         2\n",
            "\n",
            "            accuracy                           0.50         4\n",
            "           macro avg       0.50      0.25      0.33         4\n",
            "        weighted avg       1.00      0.50      0.67         4\n",
            "\n",
            "\n",
            "Text_To_Image:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Image_Editing       1.00      1.00      1.00         2\n",
            "Image_Generation       1.00      1.00      1.00         2\n",
            "\n",
            "        accuracy                           1.00         4\n",
            "       macro avg       1.00      1.00      1.00         4\n",
            "    weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Fine-tuning completed.\n",
            "\n",
            "Evaluation after fine-tuning:\n",
            "Global Classifier Performance:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Audio_To_Text       0.33      0.25      0.29         4\n",
            "Image_To_Text       0.38      0.75      0.50         4\n",
            "Text_To_Audio       1.00      0.25      0.40         4\n",
            "Text_To_Image       0.50      0.75      0.60         4\n",
            " Text_To_Text       0.50      0.25      0.33         4\n",
            "\n",
            "     accuracy                           0.45        20\n",
            "    macro avg       0.54      0.45      0.42        20\n",
            " weighted avg       0.54      0.45      0.42        20\n",
            "\n",
            "\n",
            "Sub-Classifier Performance:\n",
            "\n",
            "Image_To_Text:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "       Image_Description       0.00      0.00      0.00       2.0\n",
            "Image_Palette_Extraction       0.00      0.00      0.00       0.0\n",
            " Music_Prompt_Generation       0.00      0.00      0.00       0.0\n",
            "     OCR_Text_Extraction       0.00      0.00      0.00       2.0\n",
            "   Object_Identification       0.00      0.00      0.00       0.0\n",
            "\n",
            "                accuracy                           0.00       4.0\n",
            "               macro avg       0.00      0.00      0.00       4.0\n",
            "            weighted avg       0.00      0.00      0.00       4.0\n",
            "\n",
            "\n",
            "Text_To_Audio:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "         Code_Debugging       0.00      0.00      0.00       0.0\n",
            "      Image_Outpainting       0.00      0.00      0.00       0.0\n",
            "       Music_Generation       0.00      0.00      0.00       0.0\n",
            "Music_Prompt_Generation       0.00      0.00      0.00       0.0\n",
            "       Sound_Generation       0.00      0.00      0.00       2.0\n",
            "         Text_To_Speech       0.00      0.00      0.00       2.0\n",
            "\n",
            "               accuracy                           0.00       4.0\n",
            "              macro avg       0.00      0.00      0.00       4.0\n",
            "           weighted avg       0.00      0.00      0.00       4.0\n",
            "\n",
            "\n",
            "Text_To_Text:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "          Code_Debugging       0.00      0.00      0.00       0.0\n",
            "        Image_Inpainting       0.00      0.00      0.00       0.0\n",
            "Image_Palette_Extraction       0.00      0.00      0.00       0.0\n",
            "   Object_Identification       0.00      0.00      0.00       0.0\n",
            "      Question_Answering       0.00      0.00      0.00       2.0\n",
            "           Summarization       0.00      0.00      0.00       2.0\n",
            "\n",
            "                accuracy                           0.00       4.0\n",
            "               macro avg       0.00      0.00      0.00       4.0\n",
            "            weighted avg       0.00      0.00      0.00       4.0\n",
            "\n",
            "\n",
            "Audio_To_Text:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "       Image_Outpainting       0.00      0.00      0.00       0.0\n",
            "Image_Palette_Extraction       0.00      0.00      0.00       0.0\n",
            " Music_Prompt_Generation       0.00      0.00      0.00       0.0\n",
            "    Sound_Identification       0.00      0.00      0.00       2.0\n",
            "    Speech_Transcription       0.00      0.00      0.00       2.0\n",
            "\n",
            "                accuracy                           0.00       4.0\n",
            "               macro avg       0.00      0.00      0.00       4.0\n",
            "            weighted avg       0.00      0.00      0.00       4.0\n",
            "\n",
            "\n",
            "Text_To_Image:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "           Image_Editing       0.00      0.00      0.00       2.0\n",
            "        Image_Generation       0.00      0.00      0.00       2.0\n",
            "       Image_Outpainting       0.00      0.00      0.00       0.0\n",
            "Image_Palette_Extraction       0.00      0.00      0.00       0.0\n",
            "\n",
            "                accuracy                           0.00       4.0\n",
            "               macro avg       0.00      0.00      0.00       4.0\n",
            "            weighted avg       0.00      0.00      0.00       4.0\n",
            "\n",
            "\n",
            "Classifying new prompts:\n",
            "Prompt: 'Generate an image of a cat playing with a ball of yarn'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Outpainting\n",
            "\n",
            "Prompt: 'Convert this paragraph into a British accent speech'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Outpainting\n",
            "\n",
            "Prompt: 'What is the capital of Spain?'\n",
            "Modality: Image_To_Text\n",
            "Task: Image_Palette_Extraction\n",
            "\n",
            "Prompt: 'Describe the objects in this photograph of a living room'\n",
            "Modality: Image_To_Text\n",
            "Task: Image_Palette_Extraction\n",
            "\n",
            "Prompt: 'Transcribe this audio file of a stand-up comedy routine'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Outpainting\n",
            "\n",
            "Prompt: 'Complete the missing part of this partially damaged photo'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Inpainting\n",
            "\n",
            "Prompt: 'Create a jazz piano solo'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Generation\n",
            "\n",
            "Prompt: 'Debug this Python script that's throwing an IndexError'\n",
            "Modality: Text_To_Text\n",
            "Task: Code_Debugging\n",
            "\n",
            "Prompt: 'What are the main colors used in this abstract painting?'\n",
            "Modality: Image_To_Text\n",
            "Task: Image_Palette_Extraction\n",
            "\n",
            "Prompt: 'Generate a text description to recreate this drum beat'\n",
            "Modality: Audio_To_Text\n",
            "Task: Music_Prompt_Generation\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "class GlobalClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.classifier = OneVsRestClassifier(LinearSVC())\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_tfidf = self.vectorizer.fit_transform(X)\n",
        "        self.classifier.fit(X_tfidf, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_tfidf = self.vectorizer.transform(X)\n",
        "        return self.classifier.predict(X_tfidf)\n",
        "\n",
        "    def fine_tune(self, X, y):\n",
        "        # Combine new data with existing data\n",
        "        X_combined = list(self.classifier.classes_) + list(X)\n",
        "        y_combined = list(self.classifier.classes_) + list(y)\n",
        "\n",
        "        # Re-fit the vectorizer and classifier with the combined data\n",
        "        X_tfidf = self.vectorizer.fit_transform(X_combined)\n",
        "        self.classifier.fit(X_tfidf, y_combined)\n",
        "\n",
        "\n",
        "class SubClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.classifier = OneVsRestClassifier(LinearSVC())\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_tfidf = self.vectorizer.fit_transform(X)\n",
        "        self.classifier.fit(X_tfidf, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_tfidf = self.vectorizer.transform(X)\n",
        "        return self.classifier.predict(X_tfidf)\n",
        "\n",
        "    def fine_tune(self, X, y):\n",
        "        # Combine new data with existing data\n",
        "        X_combined = list(self.classifier.classes_) + list(X)\n",
        "        y_combined = list(self.classifier.classes_) + list(y)\n",
        "\n",
        "        # Re-fit the vectorizer and classifier with the combined data\n",
        "        X_tfidf = self.vectorizer.fit_transform(X_combined)\n",
        "        self.classifier.fit(X_tfidf, y_combined)\n",
        "\n",
        "\n",
        "class PromptClassifier:\n",
        "    def __init__(self):\n",
        "        self.global_classifier = GlobalClassifier()\n",
        "        self.sub_classifiers = {\n",
        "            \"Text_To_Image\": SubClassifier(),\n",
        "            \"Text_To_Video\": SubClassifier(),\n",
        "            \"Text_To_Audio\": SubClassifier(),\n",
        "            \"Text_To_Text\": SubClassifier(),\n",
        "            \"Image_To_Text\": SubClassifier(),\n",
        "            \"Video_To_Text\": SubClassifier(),\n",
        "            \"Audio_To_Text\": SubClassifier(),\n",
        "        }\n",
        "\n",
        "    def train(self, data):\n",
        "        # Train global classifier\n",
        "        global_X, global_y = zip(\n",
        "            *[\n",
        "                (prompt, modality)\n",
        "                for modality, tasks in data.items()\n",
        "                for task, prompts in tasks.items()\n",
        "                for prompt in prompts\n",
        "            ]\n",
        "        )\n",
        "        self.global_classifier.train(global_X, global_y)\n",
        "\n",
        "        # Train sub-classifiers\n",
        "        for modality, tasks in data.items():\n",
        "            sub_X, sub_y = zip(\n",
        "                *[\n",
        "                    (prompt, task)\n",
        "                    for task, prompts in tasks.items()\n",
        "                    for prompt in prompts\n",
        "                ]\n",
        "            )\n",
        "            self.sub_classifiers[modality].train(sub_X, sub_y)\n",
        "\n",
        "    def classify(self, prompt):\n",
        "        # First level: Global classification\n",
        "        modality = self.global_classifier.predict([prompt])[0]\n",
        "\n",
        "        # Second level: Sub-classification\n",
        "        task = self.sub_classifiers[modality].predict([prompt])[0]\n",
        "\n",
        "        return modality, task\n",
        "\n",
        "    def fine_tune(self, new_data):\n",
        "        # Fine-tune global classifier\n",
        "        global_X, global_y = zip(\n",
        "            *[\n",
        "                (prompt, modality)\n",
        "                for modality, tasks in new_data.items()\n",
        "                for task, prompts in tasks.items()\n",
        "                for prompt in prompts\n",
        "            ]\n",
        "        )\n",
        "        self.global_classifier.fine_tune(global_X, global_y)\n",
        "\n",
        "        # Fine-tune sub-classifiers\n",
        "        for modality, tasks in new_data.items():\n",
        "            sub_X, sub_y = zip(\n",
        "                *[\n",
        "                    (prompt, task)\n",
        "                    for task, prompts in tasks.items()\n",
        "                    for prompt in prompts\n",
        "                ]\n",
        "            )\n",
        "            self.sub_classifiers[modality].fine_tune(sub_X, sub_y)\n",
        "\n",
        "        print(\"Fine-tuning completed.\")\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        true_modalities, true_tasks, prompts = [], [], []\n",
        "        for modality, tasks in test_data.items():\n",
        "            for task, task_prompts in tasks.items():\n",
        "                true_modalities.extend([modality] * len(task_prompts))\n",
        "                true_tasks.extend([task] * len(task_prompts))\n",
        "                prompts.extend(task_prompts)\n",
        "\n",
        "        predicted_modalities, predicted_tasks = zip(\n",
        "            *[self.classify(prompt) for prompt in prompts]\n",
        "        )\n",
        "\n",
        "        print(\"Global Classifier Performance:\")\n",
        "        print(classification_report(true_modalities, predicted_modalities))\n",
        "\n",
        "        print(\"\\nSub-Classifier Performance:\")\n",
        "        for modality in set(true_modalities):\n",
        "            modality_mask = np.array(true_modalities) == modality\n",
        "            print(f\"\\n{modality}:\")\n",
        "            print(\n",
        "                classification_report(\n",
        "                    np.array(true_tasks)[modality_mask],\n",
        "                    np.array(predicted_tasks)[modality_mask],\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initial training data (same as before)\n",
        "    data = {\n",
        "        \"Text_To_Image\": {\n",
        "            \"Image_Generation\": [\n",
        "                \"Generate a photorealistic image of a snow-capped mountain at sunrise\",\n",
        "                \"Create a digital painting of a bustling medieval marketplace\",\n",
        "                \"Produce an anime-style portrait of a cyberpunk character\",\n",
        "                \"Generate a vector illustration of a tropical bird in flight\",\n",
        "                \"Create a surrealist image combining elements of clocks and butterflies\",\n",
        "                \"Generate a realistic 3D render of a futuristic sports car\",\n",
        "                \"Create a watercolor-style landscape of a serene Japanese garden\",\n",
        "                \"Produce a pixel art scene of a space battle between alien ships\",\n",
        "                \"Generate an abstract representation of the concept of time\",\n",
        "                \"Create a detailed architectural blueprint of a sustainable treehouse\",\n",
        "            ],\n",
        "            \"Image_Editing\": [\n",
        "                \"Remove the background from this product photo and replace it with a pure white backdrop\",\n",
        "                \"Enhance the clarity and sharpness of this blurry landscape photograph\",\n",
        "                \"Colorize this black and white historical image of New York City in the 1920s\",\n",
        "                \"Adjust the lighting in this portrait to create a dramatic chiaroscuro effect\",\n",
        "                \"Seamlessly remove the person standing in the foreground of this tourist photo\",\n",
        "                \"Apply a vintage film grain effect to this digital photograph\",\n",
        "                \"Correct the perspective distortion in this architectural photograph\",\n",
        "                \"Retouch this fashion photo to smooth skin textures and enhance eye colors\",\n",
        "                \"Create a tilt-shift effect on this cityscape to make it appear miniature\",\n",
        "                \"Composite multiple exposures of a lunar eclipse into a single image\",\n",
        "            ],\n",
        "        },\n",
        "        \"Text_To_Audio\": {\n",
        "            \"Text_To_Speech\": [\n",
        "                \"Convert this academic paper on quantum physics into spoken words with proper scientific pronunciation\",\n",
        "                \"Read this children's bedtime story with different voices for each character\",\n",
        "                \"Narrate this news article in the style of a professional newscaster\",\n",
        "                \"Transform this motivational quote into an inspiring spoken affirmation\",\n",
        "                \"Convert this technical manual into clear, articulate speech for a video tutorial\",\n",
        "                \"Read this poem with appropriate rhythm and emotional inflection\",\n",
        "                \"Narrate this historical document in the accent of its original time period\",\n",
        "                \"Convert this recipe into step-by-step audio instructions for a cooking podcast\",\n",
        "                \"Read this legal contract with clear enunciation of complex terms\",\n",
        "                \"Transform this movie script into a dramatic audio performance with multiple voices\",\n",
        "            ],\n",
        "            \"Sound_Generation\": [\n",
        "                \"Create a 30-second ambient sound of a peaceful forest with birds chirping and leaves rustling\",\n",
        "                \"Generate the sound of a bustling coffee shop with background chatter and espresso machines\",\n",
        "                \"Produce a soundscape of a thunderstorm approaching, peaking, and then receding\",\n",
        "                \"Create the audio atmosphere of an alien planet with strange, otherworldly sounds\",\n",
        "                \"Generate a loopable background track for meditation with gentle bells and flowing water\",\n",
        "                \"Produce the sound of a car engine starting, idling, and then accelerating\",\n",
        "                \"Create a realistic audio simulation of waves crashing on a rocky shore\",\n",
        "                \"Generate the ambient sound of a busy hospital emergency room\",\n",
        "                \"Produce a 1-minute track of futuristic computer and machinery sounds\",\n",
        "                \"Create the audio experience of being in the middle of a cheering stadium crowd\",\n",
        "            ],\n",
        "        },\n",
        "        \"Text_To_Text\": {\n",
        "            \"Question_Answering\": [\n",
        "                \"What are the main causes and effects of climate change?\",\n",
        "                \"Explain the process of photosynthesis in simple terms\",\n",
        "                \"Who were the key figures in the American Civil Rights Movement?\",\n",
        "                \"What is the difference between machine learning and deep learning?\",\n",
        "                \"How does the human immune system work to fight off infections?\",\n",
        "                \"What are the primary arguments for and against universal basic income?\",\n",
        "                \"Explain the concept of quantum entanglement in layman's terms\",\n",
        "                \"What were the main causes of the French Revolution?\",\n",
        "                \"How does blockchain technology work and what are its potential applications?\",\n",
        "                \"What is the current scientific understanding of dark matter and dark energy?\",\n",
        "            ],\n",
        "            \"Summarization\": [\n",
        "                \"Provide a concise summary of the plot of 'To Kill a Mockingbird'\",\n",
        "                \"Summarize the key findings of the latest IPCC report on climate change\",\n",
        "                \"Give an overview of the major events of World War II in chronological order\",\n",
        "                \"Summarize the main principles of Maslow's hierarchy of needs\",\n",
        "                \"Provide a brief explanation of the theory of evolution by natural selection\",\n",
        "                \"Summarize the key points of Martin Luther King Jr.'s 'I Have a Dream' speech\",\n",
        "                \"Give an overview of the major schools of thought in philosophy\",\n",
        "                \"Summarize the plot and themes of George Orwell's '1984'\",\n",
        "                \"Provide a concise explanation of how the stock market works\",\n",
        "                \"Summarize the current understanding of the human microbiome and its importance\",\n",
        "            ],\n",
        "        },\n",
        "        \"Image_To_Text\": {\n",
        "            \"Image_Description\": [\n",
        "                \"Describe in detail the composition and subject matter of this abstract painting\",\n",
        "                \"What can you tell me about the architectural style and features of the building in this photograph?\",\n",
        "                \"Analyze the body language and facial expressions of the people in this group photo\",\n",
        "                \"Describe the natural landscape features visible in this satellite image\",\n",
        "                \"What details can you provide about the fashion and time period depicted in this historical photograph?\",\n",
        "                \"Describe the layout and key elements of this infographic about renewable energy\",\n",
        "                \"What can you tell me about the species and behavior of the animals shown in this wildlife photo?\",\n",
        "                \"Analyze the use of color, light, and shadow in this Renaissance painting\",\n",
        "                \"Describe the key features and condition of the artifact shown in this archaeological photograph\",\n",
        "                \"What technical details can you provide about the car model shown in this image?\",\n",
        "            ],\n",
        "            \"OCR_Text_Extraction\": [\n",
        "                \"Extract and transcribe all text visible on the street signs and storefronts in this city photograph\",\n",
        "                \"Read and list all the ingredients from this image of a nutrition label\",\n",
        "                \"Transcribe the handwritten text in this image of an old letter\",\n",
        "                \"Extract all text from this photograph of a complex scientific diagram with annotations\",\n",
        "                \"Read and organize the text from this image of a restaurant menu\",\n",
        "                \"Transcribe the text from this photograph of an ancient stone inscription\",\n",
        "                \"Extract and format the text from this image of a business card\",\n",
        "                \"Read and list all the book titles visible on the spines in this bookshelf image\",\n",
        "                \"Transcribe the text from this image of a historical document with old-style typography\",\n",
        "                \"Extract all visible text from this photograph of a cluttered bulletin board\",\n",
        "            ],\n",
        "        },\n",
        "        \"Audio_To_Text\": {\n",
        "            \"Sound_Identification\": [\n",
        "                \"Identify the types of birds singing in this audio recording from a rainforest\",\n",
        "                \"What musical instruments can you hear in this orchestral performance?\",\n",
        "                \"Identify the make and model of the car based on the engine sound in this audio clip\",\n",
        "                \"What types of weather phenomena can be heard in this outdoor ambient recording?\",\n",
        "                \"Identify the genre and potential decade of origin for this music clip\",\n",
        "                \"What types of animals can be heard in this nighttime audio recording?\",\n",
        "                \"Identify the different kitchen appliances operating in this audio clip\",\n",
        "                \"What types of emergency vehicles can be heard in this urban soundscape?\",\n",
        "                \"Identify the different sports being played based on the sounds in this recording\",\n",
        "                \"What types of power tools or machinery can be heard in this construction site audio?\",\n",
        "            ],\n",
        "            \"Speech_Transcription\": [\n",
        "                \"Transcribe this audio recording of a fast-paced debate, identifying speakers where possible\",\n",
        "                \"Provide a verbatim transcription of this technical lecture, including any specialized terms\",\n",
        "                \"Transcribe this audio of a news broadcast, including any non-speech audio cues\",\n",
        "                \"Create a time-stamped transcript of this podcast interview\",\n",
        "                \"Transcribe this audio recording of a courtroom proceeding, noting speaker changes\",\n",
        "                \"Provide a transcript of this multi-language business meeting, noting the language switches\",\n",
        "                \"Transcribe this historical speech recording, noting any areas of uncertainty due to audio quality\",\n",
        "                \"Create a transcript of this stand-up comedy routine, noting audience reactions\",\n",
        "                \"Transcribe this audio diary entry, including any emotional cues in the speaker's voice\",\n",
        "                \"Provide a detailed transcript of this conference call, identifying each participant\",\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "    # Initialize and train the classifier\n",
        "    classifier = PromptClassifier()\n",
        "    classifier.train(data)\n",
        "\n",
        "    # Test data for evaluation\n",
        "    test_data = {\n",
        "        \"Text_To_Image\": {\n",
        "            \"Image_Generation\": [\n",
        "                \"Create an image of a flying dragon\",\n",
        "                \"Generate a picture of a cyberpunk street\",\n",
        "            ],\n",
        "            \"Image_Editing\": [\n",
        "                \"Crop this image to a square\",\n",
        "                \"Increase the contrast of this photo\",\n",
        "            ],\n",
        "        },\n",
        "        \"Text_To_Audio\": {\n",
        "            \"Text_To_Speech\": [\n",
        "                \"Read this news article aloud\",\n",
        "                \"Convert this poem to speech\",\n",
        "            ],\n",
        "            \"Sound_Generation\": [\n",
        "                \"Create the sound of a busy city\",\n",
        "                \"Generate a bird chirping sound\",\n",
        "            ],\n",
        "        },\n",
        "        \"Text_To_Text\": {\n",
        "            \"Question_Answering\": [\n",
        "                \"Who won the Nobel Prize in Physics in 2022?\",\n",
        "                \"What is the boiling point of water?\",\n",
        "            ],\n",
        "            \"Summarization\": [\n",
        "                \"Summarize the plot of Romeo and Juliet\",\n",
        "                \"Give an overview of the French Revolution\",\n",
        "            ],\n",
        "        },\n",
        "        \"Image_To_Text\": {\n",
        "            \"Image_Description\": [\n",
        "                \"What do you see in this landscape photo?\",\n",
        "                \"Describe the contents of this infographic\",\n",
        "            ],\n",
        "            \"OCR_Text_Extraction\": [\n",
        "                \"Read the text on this street sign\",\n",
        "                \"Extract the words from this scanned document\",\n",
        "            ],\n",
        "        },\n",
        "        \"Audio_To_Text\": {\n",
        "            \"Sound_Identification\": [\n",
        "                \"What type of animal is making this sound?\",\n",
        "                \"Identify the genre of this music clip\",\n",
        "            ],\n",
        "            \"Speech_Transcription\": [\n",
        "                \"Convert this podcast episode to text\",\n",
        "                \"Transcribe this recorded lecture\",\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    print(\"Initial Evaluation:\")\n",
        "    classifier.evaluate(test_data)\n",
        "\n",
        "    # New data for fine-tuning\n",
        "    new_data = {\n",
        "        \"Text_To_Image\": {\n",
        "            \"Image_Inpainting\": [\n",
        "                \"Fill in the missing parts of this torn photograph\",\n",
        "                \"Complete the blanked-out areas in this image\",\n",
        "            ],\n",
        "            \"Image_Outpainting\": [\n",
        "                \"Extend this image beyond its current borders\",\n",
        "                \"Add more scenery around the edges of this picture\",\n",
        "            ],\n",
        "        },\n",
        "        \"Text_To_Audio\": {\n",
        "            \"Music_Generation\": [\n",
        "                \"Compose a short melody in the style of Mozart\",\n",
        "                \"Create a hip-hop beat with a strong bassline\",\n",
        "            ],\n",
        "        },\n",
        "        \"Text_To_Text\": {\n",
        "            \"Code_Generation\": [\n",
        "                \"Write a Python function to calculate Fibonacci numbers\",\n",
        "                \"Create a JavaScript function for form validation\",\n",
        "            ],\n",
        "            \"Code_Debugging\": [\n",
        "                \"Find and fix the bug in this C++ code\",\n",
        "                \"Debug this SQL query that's producing incorrect results\",\n",
        "            ],\n",
        "        },\n",
        "        \"Image_To_Text\": {\n",
        "            \"Object_Identification\": [\n",
        "                \"List all the objects you can see in this kitchen scene\",\n",
        "                \"Identify the animals present in this wildlife photo\",\n",
        "            ],\n",
        "            \"Image_Palette_Extraction\": [\n",
        "                \"What are the dominant colors in this painting?\",\n",
        "                \"Describe the color scheme of this product packaging\",\n",
        "            ],\n",
        "        },\n",
        "        \"Audio_To_Text\": {\n",
        "            \"Music_Prompt_Generation\": [\n",
        "                \"Describe this classical music piece in words\",\n",
        "                \"Generate a text prompt to recreate this electronic music track\",\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Fine-tune the classifier\n",
        "    classifier.fine_tune(new_data)\n",
        "\n",
        "    # Re-evaluate after fine-tuning\n",
        "    print(\"\\nEvaluation after fine-tuning:\")\n",
        "    classifier.evaluate(test_data)\n",
        "\n",
        "    # Test the classifier with new prompts\n",
        "    test_prompts = [\n",
        "        \"Generate an image of a cat playing with a ball of yarn\",\n",
        "        \"Convert this paragraph into a British accent speech\",\n",
        "        \"What is the capital of Spain?\",\n",
        "        \"Describe the objects in this photograph of a living room\",\n",
        "        \"Transcribe this audio file of a stand-up comedy routine\",\n",
        "        \"Complete the missing part of this partially damaged photo\",\n",
        "        \"Create a jazz piano solo\",\n",
        "        \"Debug this Python script that's throwing an IndexError\",\n",
        "        \"What are the main colors used in this abstract painting?\",\n",
        "        \"Generate a text description to recreate this drum beat\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\nClassifying new prompts:\")\n",
        "    for prompt in test_prompts:\n",
        "        modality, task = classifier.classify(prompt)\n",
        "        print(f\"Prompt: '{prompt}'\")\n",
        "        print(f\"Modality: {modality}\")\n",
        "        print(f\"Task: {task}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnTWFP5oL4I7"
      },
      "source": [
        "## external curated dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q02VWkl7MBA8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg4qw1QrMMKR"
      },
      "outputs": [],
      "source": [
        "# DATASET JSON FORMAT\n",
        "json_dataset = \"\"\"\n",
        "  {\n",
        "    \"version\": \"1.0\",\n",
        "    \"date_created\": \"2023-05-24\",\n",
        "    \"total_prompts\": 1000,\n",
        "    \"data\": [\n",
        "      {\n",
        "        \"id\": \"001\",\n",
        "        \"prompt\": \"Generate an image of a sunset over a mountain range\",\n",
        "        \"modality\": \"Text_To_Image\",\n",
        "        \"task\": \"Image_Generation\",\n",
        "        \"difficulty\": \"easy\",\n",
        "        \"tags\": [\"nature\", \"landscape\", \"generation\"],\n",
        "        \"source\": \"manual_creation\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"002\",\n",
        "        \"prompt\": \"Remove the background from this portrait photo\",\n",
        "        \"modality\": \"Text_To_Image\",\n",
        "        \"task\": \"Image_Editing\",\n",
        "        \"difficulty\": \"medium\",\n",
        "        \"tags\": [\"portrait\", \"editing\", \"background_removal\"],\n",
        "        \"source\": \"user_submitted\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"003\",\n",
        "        \"prompt\": \"Convert this paragraph into spoken words with a British accent\",\n",
        "        \"modality\": \"Text_To_Audio\",\n",
        "        \"task\": \"Text_To_Speech\",\n",
        "        \"difficulty\": \"medium\",\n",
        "        \"tags\": [\"speech\", \"accent\", \"british\"],\n",
        "        \"source\": \"manual_creation\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"004\",\n",
        "        \"prompt\": \"What is the capital of France?\",\n",
        "        \"modality\": \"Text_To_Text\",\n",
        "        \"task\": \"Question_Answering\",\n",
        "        \"difficulty\": \"easy\",\n",
        "        \"tags\": [\"geography\", \"general_knowledge\"],\n",
        "        \"source\": \"manual_creation\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"005\",\n",
        "        \"prompt\": \"Describe the objects visible in this kitchen scene\",\n",
        "        \"modality\": \"Image_To_Text\",\n",
        "        \"task\": \"Object_Identification\",\n",
        "        \"difficulty\": \"medium\",\n",
        "        \"tags\": [\"kitchen\", \"objects\", \"description\"],\n",
        "        \"source\": \"user_submitted\"\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"006\",\n",
        "        \"prompt\": \"Transcribe this audio recording of a business meeting\",\n",
        "        \"modality\": \"Audio_To_Text\",\n",
        "        \"task\": \"Speech_Transcription\",\n",
        "        \"difficulty\": \"hard\",\n",
        "        \"tags\": [\"business\", \"transcription\", \"meeting\"],\n",
        "        \"source\": \"manual_creation\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        dataset = json.load(file)\n",
        "    return dataset\n",
        "\n",
        "# Usage\n",
        "dataset = load_dataset('prompts_dataset.json')\n",
        "prompts = dataset['data']\n",
        "\n",
        "# Process the prompts\n",
        "for prompt in prompts:\n",
        "    print(f\"Modality: {prompt['modality']}, Task: {prompt['task']}\")\n",
        "    print(f\"Prompt: {prompt['prompt']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKjpA0jtMhIF"
      },
      "source": [
        " a function that converts the JSON format we discussed earlier into the nested dictionary format used for training and fine-tuning the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L08GrBXCL32G"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "def json_to_training_data(json_file_path):\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        dataset = json.load(file)\n",
        "\n",
        "    training_data = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "    for entry in dataset['data']:\n",
        "        modality = entry['modality']\n",
        "        task = entry['task']\n",
        "        prompt = entry['prompt']\n",
        "        training_data[modality][task].append(prompt)\n",
        "\n",
        "    return dict(training_data)\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    json_file_path = 'prompts_dataset.json'\n",
        "    training_data = json_to_training_data(json_file_path)\n",
        "\n",
        "    # Print the resulting structure\n",
        "    for modality, tasks in training_data.items():\n",
        "        print(f\"{modality}:\")\n",
        "        for task, prompts in tasks.items():\n",
        "            print(f\"  {task}:\")\n",
        "            for prompt in prompts:\n",
        "                print(f\"    - {prompt}\")\n",
        "        print()\n",
        "\n",
        "    # You can now use this data for training or fine-tuning\n",
        "    classifier = PromptClassifier()\n",
        "    classifier.train(training_data)\n",
        "\n",
        "    # Or for fine-tuning\n",
        "    classifier.fine_tune(training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Cl3HwzRQon"
      },
      "source": [
        "### Removing the outpainting and inpainting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zf-IEO1wRU5u"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifying test prompts:\n",
            "Prompt: 'Generate an image of a cat playing with a ball'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Convert this paragraph into speech'\n",
            "Modality: Text_To_Audio\n",
            "Task: Text_To_Speech\n",
            "\n",
            "Prompt: 'What is the capital of Spain?'\n",
            "Modality: Text_To_Text\n",
            "Task: Question_Answering\n",
            "\n",
            "Prompt: 'Describe the objects in this photograph'\n",
            "Modality: Image_To_Text\n",
            "Task: Image_Description\n",
            "\n",
            "Prompt: 'Transcribe this audio file of a business meeting'\n",
            "Modality: Audio_To_Text\n",
            "Task: Speech_Transcription\n",
            "\n",
            "Prompt: 'Edit this image to make the sky more vibrant'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Editing\n",
            "\n",
            "Prompt: 'Create a digital painting of a futuristic cityscape'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Remove the background from this product image'\n",
            "Modality: Image_To_Text\n",
            "Task: OCR_Text_Extraction\n",
            "\n",
            "Prompt: 'Generate a sound effect of a car horn honking'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Summarize the main points of this research paper'\n",
            "Modality: Text_To_Text\n",
            "Task: Summarization\n",
            "\n",
            "\n",
            "Adding new examples and testing:\n",
            "Prompt: 'Create a photorealistic image of a futuristic underwater city'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Translate this English text to French'\n",
            "Modality: Text_To_Text\n",
            "Task: Language_Translation\n",
            "\n",
            "Prompt: 'Create a 10-second animation of a blooming flower'\n",
            "Modality: Text_To_Image\n",
            "Task: Image_Generation\n",
            "\n",
            "Prompt: 'Add subtitles to this video clip'\n",
            "Modality: Audio_To_Text\n",
            "Task: Sound_Identification\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "class PromptClassifier:\n",
        "    def __init__(self):\n",
        "        self.modality_classifier = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "        self.task_classifiers = {}\n",
        "        self.data = {}\n",
        "\n",
        "    def train(self, data):\n",
        "        self.data = data\n",
        "        self._train()\n",
        "\n",
        "    def _train(self):\n",
        "        # Prepare data for modality classification\n",
        "        X_modality = []\n",
        "        y_modality = []\n",
        "        task_data = {}\n",
        "\n",
        "        for modality, tasks in self.data.items():\n",
        "            for task, prompts in tasks.items():\n",
        "                for prompt in prompts:\n",
        "                    X_modality.append(prompt)\n",
        "                    y_modality.append(modality)\n",
        "\n",
        "                    if modality not in task_data:\n",
        "                        task_data[modality] = {\"X\": [], \"y\": []}\n",
        "                    task_data[modality][\"X\"].append(prompt)\n",
        "                    task_data[modality][\"y\"].append(task)\n",
        "\n",
        "        # Train modality classifier\n",
        "        self.modality_classifier.fit(X_modality, y_modality)\n",
        "\n",
        "        # Train task classifiers for each modality\n",
        "        for modality, modality_data in task_data.items():\n",
        "            self.task_classifiers[modality] = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "            self.task_classifiers[modality].fit(modality_data[\"X\"], modality_data[\"y\"])\n",
        "\n",
        "    def classify(self, prompt):\n",
        "        modality = self.modality_classifier.predict([prompt])[0]\n",
        "        task = self.task_classifiers[modality].predict([prompt])[0]\n",
        "        return modality, task\n",
        "\n",
        "    def add_example(self, modality, task, prompt):\n",
        "        if modality not in self.data:\n",
        "            self.data[modality] = {}\n",
        "        if task not in self.data[modality]:\n",
        "            self.data[modality][task] = []\n",
        "        self.data[modality][task].append(prompt)\n",
        "        self._train()\n",
        "\n",
        "    def add_task(self, modality, task, prompts):\n",
        "        if modality not in self.data:\n",
        "            self.data[modality] = {}\n",
        "        self.data[modality][task] = prompts\n",
        "        self._train()\n",
        "\n",
        "    def add_modality(self, modality, tasks):\n",
        "        self.data[modality] = tasks\n",
        "        self._train()\n",
        "\n",
        "# Training data\n",
        "data = {\n",
        "    \"Text_To_Image\": {\n",
        "        \"Image_Generation\": [\n",
        "            \"Generate a photorealistic image of a snow-capped mountain at sunrise\",\n",
        "            \"Create a digital painting of a bustling medieval marketplace\",\n",
        "            \"Produce an anime-style portrait of a cyberpunk character\",\n",
        "            \"Generate a vector illustration of a tropical bird in flight\",\n",
        "            \"Create a surrealist image combining elements of clocks and butterflies\",\n",
        "            \"Generate a realistic 3D render of a futuristic sports car\",\n",
        "            \"Create a watercolor-style landscape of a serene Japanese garden\",\n",
        "            \"Produce a pixel art scene of a space battle between alien ships\",\n",
        "            \"Generate an abstract representation of the concept of time\",\n",
        "            \"Create a detailed architectural blueprint of a sustainable treehouse\"\n",
        "        ],\n",
        "        \"Image_Editing\": [\n",
        "            \"Remove the background from this product photo and replace it with a pure white backdrop\",\n",
        "            \"Enhance the clarity and sharpness of this blurry landscape photograph\",\n",
        "            \"Colorize this black and white historical image of New York City in the 1920s\",\n",
        "            \"Adjust the lighting in this portrait to create a dramatic chiaroscuro effect\",\n",
        "            \"Seamlessly remove the person standing in the foreground of this tourist photo\",\n",
        "            \"Apply a vintage film grain effect to this digital photograph\",\n",
        "            \"Correct the perspective distortion in this architectural photograph\",\n",
        "            \"Retouch this fashion photo to smooth skin textures and enhance eye colors\",\n",
        "            \"Create a tilt-shift effect on this cityscape to make it appear miniature\",\n",
        "            \"Composite multiple exposures of a lunar eclipse into a single image\"\n",
        "        ],\n",
        "    },\n",
        "    \"Text_To_Audio\": {\n",
        "        \"Text_To_Speech\": [\n",
        "            \"Convert this academic paper on quantum physics into spoken words with proper scientific pronunciation\",\n",
        "            \"Read this children's bedtime story with different voices for each character\",\n",
        "            \"Narrate this news article in the style of a professional newscaster\",\n",
        "            \"Transform this motivational quote into an inspiring spoken affirmation\",\n",
        "            \"Convert this technical manual into clear, articulate speech for a video tutorial\",\n",
        "            \"Read this poem with appropriate rhythm and emotional inflection\",\n",
        "            \"Narrate this historical document in the accent of its original time period\",\n",
        "            \"Convert this recipe into step-by-step audio instructions for a cooking podcast\",\n",
        "            \"Read this legal contract with clear enunciation of complex terms\",\n",
        "            \"Transform this movie script into a dramatic audio performance with multiple voices\"\n",
        "        ],\n",
        "        \"Sound_Generation\": [\n",
        "            \"Create a 30-second ambient sound of a peaceful forest with birds chirping and leaves rustling\",\n",
        "            \"Generate the sound of a bustling coffee shop with background chatter and espresso machines\",\n",
        "            \"Produce a soundscape of a thunderstorm approaching, peaking, and then receding\",\n",
        "            \"Create the audio atmosphere of an alien planet with strange, otherworldly sounds\",\n",
        "            \"Generate a loopable background track for meditation with gentle bells and flowing water\",\n",
        "            \"Produce the sound of a car engine starting, idling, and then accelerating\",\n",
        "            \"Create a realistic audio simulation of waves crashing on a rocky shore\",\n",
        "            \"Generate the ambient sound of a busy hospital emergency room\",\n",
        "            \"Produce a 1-minute track of futuristic computer and machinery sounds\",\n",
        "            \"Create the audio experience of being in the middle of a cheering stadium crowd\"\n",
        "        ],\n",
        "    },\n",
        "    \"Text_To_Text\": {\n",
        "        \"Question_Answering\": [\n",
        "            \"What are the main causes and effects of climate change?\",\n",
        "            \"Explain the process of photosynthesis in simple terms\",\n",
        "            \"Who were the key figures in the American Civil Rights Movement?\",\n",
        "            \"What is the difference between machine learning and deep learning?\",\n",
        "            \"How does the human immune system work to fight off infections?\",\n",
        "            \"What are the primary arguments for and against universal basic income?\",\n",
        "            \"Explain the concept of quantum entanglement in layman's terms\",\n",
        "            \"What were the main causes of the French Revolution?\",\n",
        "            \"How does blockchain technology work and what are its potential applications?\",\n",
        "            \"What is the current scientific understanding of dark matter and dark energy?\"\n",
        "        ],\n",
        "        \"Summarization\": [\n",
        "            \"Provide a concise summary of the plot of 'To Kill a Mockingbird'\",\n",
        "            \"Summarize the key findings of the latest IPCC report on climate change\",\n",
        "            \"Give an overview of the major events of World War II in chronological order\",\n",
        "            \"Summarize the main principles of Maslow's hierarchy of needs\",\n",
        "            \"Provide a brief explanation of the theory of evolution by natural selection\",\n",
        "            \"Summarize the key points of Martin Luther King Jr.'s 'I Have a Dream' speech\",\n",
        "            \"Give an overview of the major schools of thought in philosophy\",\n",
        "            \"Summarize the plot and themes of George Orwell's '1984'\",\n",
        "            \"Provide a concise explanation of how the stock market works\",\n",
        "            \"Summarize the current understanding of the human microbiome and its importance\"\n",
        "        ],\n",
        "    },\n",
        "    \"Image_To_Text\": {\n",
        "        \"Image_Description\": [\n",
        "            \"Describe in detail the composition and subject matter of this abstract painting\",\n",
        "            \"What can you tell me about the architectural style and features of the building in this photograph?\",\n",
        "            \"Analyze the body language and facial expressions of the people in this group photo\",\n",
        "            \"Describe the natural landscape features visible in this satellite image\",\n",
        "            \"What details can you provide about the fashion and time period depicted in this historical photograph?\",\n",
        "            \"Describe the layout and key elements of this infographic about renewable energy\",\n",
        "            \"What can you tell me about the species and behavior of the animals shown in this wildlife photo?\",\n",
        "            \"Analyze the use of color, light, and shadow in this Renaissance painting\",\n",
        "            \"Describe the key features and condition of the artifact shown in this archaeological photograph\",\n",
        "            \"What technical details can you provide about the car model shown in this image?\"\n",
        "        ],\n",
        "        \"OCR_Text_Extraction\": [\n",
        "            \"Extract and transcribe all text visible on the street signs and storefronts in this city photograph\",\n",
        "            \"Read and list all the ingredients from this image of a nutrition label\",\n",
        "            \"Transcribe the handwritten text in this image of an old letter\",\n",
        "            \"Extract all text from this photograph of a complex scientific diagram with annotations\",\n",
        "            \"Read and organize the text from this image of a restaurant menu\",\n",
        "            \"Transcribe the text from this photograph of an ancient stone inscription\",\n",
        "            \"Extract and format the text from this image of a business card\",\n",
        "            \"Read and list all the book titles visible on the spines in this bookshelf image\",\n",
        "            \"Transcribe the text from this image of a historical document with old-style typography\",\n",
        "            \"Extract all visible text from this photograph of a cluttered bulletin board\"\n",
        "        ],\n",
        "    },\n",
        "    \"Audio_To_Text\": {\n",
        "        \"Sound_Identification\": [\n",
        "            \"Identify the types of birds singing in this audio recording from a rainforest\",\n",
        "            \"What musical instruments can you hear in this orchestral performance?\",\n",
        "            \"Identify the make and model of the car based on the engine sound in this audio clip\",\n",
        "            \"What types of weather phenomena can be heard in this outdoor ambient recording?\",\n",
        "            \"Identify the genre and potential decade of origin for this music clip\",\n",
        "            \"What types of animals can be heard in this nighttime audio recording?\",\n",
        "            \"Identify the different kitchen appliances operating in this audio clip\",\n",
        "            \"What types of emergency vehicles can be heard in this urban soundscape?\",\n",
        "            \"Identify the different sports being played based on the sounds in this recording\",\n",
        "            \"What types of power tools or machinery can be heard in this construction site audio?\"\n",
        "        ],\n",
        "        \"Speech_Transcription\": [\n",
        "            \"Transcribe this audio recording of a fast-paced debate, identifying speakers where possible\",\n",
        "            \"Provide a verbatim transcription of this technical lecture, including any specialized terms\",\n",
        "            \"Transcribe this audio of a news broadcast, including any non-speech audio cues\",\n",
        "            \"Create a time-stamped transcript of this podcast interview\",\n",
        "            \"Transcribe this audio recording of a courtroom proceeding, noting speaker changes\",\n",
        "            \"Provide a transcript of this multi-language business meeting, noting the language switches\",\n",
        "            \"Transcribe this historical speech recording, noting any areas of uncertainty due to audio quality\",\n",
        "            \"Create a transcript of this stand-up comedy routine, noting audience reactions\",\n",
        "            \"Transcribe this audio diary entry, including any emotional cues in the speaker's voice\",\n",
        "            \"Provide a detailed transcript of this conference call, identifying each participant\"\n",
        "        ],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Initialize and train the classifier\n",
        "classifier = PromptClassifier()\n",
        "classifier.train(data)\n",
        "\n",
        "# Test the classifier\n",
        "test_prompts = [\n",
        "    \"Generate an image of a cat playing with a ball\",\n",
        "    \"Convert this paragraph into speech\",\n",
        "    \"What is the capital of Spain?\",\n",
        "    \"Describe the objects in this photograph\",\n",
        "    \"Transcribe this audio file of a business meeting\",\n",
        "    \"Edit this image to make the sky more vibrant\",\n",
        "    \"Create a digital painting of a futuristic cityscape\",\n",
        "    \"Remove the background from this product image\",\n",
        "    \"Generate a sound effect of a car horn honking\",\n",
        "    \"Summarize the main points of this research paper\"\n",
        "]\n",
        "\n",
        "print(\"Classifying test prompts:\")\n",
        "for prompt in test_prompts:\n",
        "    modality, task = classifier.classify(prompt)\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Modality: {modality}\")\n",
        "    print(f\"Task: {task}\\n\")\n",
        "\n",
        "# Example of fine-tuning\n",
        "print(\"\\nAdding new examples and testing:\")\n",
        "\n",
        "# Add a new example to an existing task\n",
        "classifier.add_example(\"Text_To_Image\", \"Image_Generation\", \"Create a photorealistic image of a futuristic underwater city\")\n",
        "\n",
        "# Add a new task to an existing modality\n",
        "classifier.add_task(\"Text_To_Text\", \"Language_Translation\", [\n",
        "    \"Translate this English text to French\",\n",
        "    \"Convert this Spanish paragraph to German\",\n",
        "    \"Translate this Chinese sentence to Russian\"\n",
        "])\n",
        "\n",
        "# Add a new modality with tasks\n",
        "classifier.add_modality(\"Text_To_Video\", {\n",
        "    \"Video_Generation\": [\n",
        "        \"Create a 10-second animation of a blooming flower\",\n",
        "        \"Generate a short video clip of ocean waves crashing on a beach\"\n",
        "    ],\n",
        "    \"Video_Editing\": [\n",
        "        \"Add subtitles to this video clip\",\n",
        "        \"Adjust the color grading of this video to have a warmer tone\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Test the updated classifier\n",
        "new_test_prompts = [\n",
        "    \"Create a photorealistic image of a futuristic underwater city\",\n",
        "    \"Translate this English text to French\",\n",
        "    \"Create a 10-second animation of a blooming flower\",\n",
        "    \"Add subtitles to this video clip\"\n",
        "]\n",
        "\n",
        "for prompt in new_test_prompts:\n",
        "    modality, task = classifier.classify(prompt)\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Modality: {modality}\")\n",
        "    print(f\"Task: {task}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2022.10.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
